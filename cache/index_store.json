{"docstore/data":{"4ea2f040-36a1-45dd-8c32-83478ffaa1b1":{"indexId":"4ea2f040-36a1-45dd-8c32-83478ffaa1b1","nodesDict":{"93da281a-1695-4b72-aa77-f6ea92bf2636":{"id_":"93da281a-1695-4b72-aa77-f6ea92bf2636","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"AkyOzszqzzCLgoTx0mLXqNB85N11dXEcCP+hZnI6kCo=","metadata":{},"hash":"u35OMvcCoe3ropCtcREzPaB3C4WqhUCFBjI9cdRB21I="},"NEXT":{"nodeId":"0d67b29e-8102-4ca6-8395-48d1833eb818","metadata":{},"hash":"T2Wng9qC3yilHvpze05MI8Hcg3V9mhGaBkoB+4nUkFA="}},"hash":"CsoSlOAwk/CSQebkcH5eyIAX09H/8IBIrrakYGDzyNQ=","text":"Generative Agents: Interactive Simulacra of Human Behavior\r\nJoon Sung Park\r\nStanford University\r\nStanford, USA\r\njoonspk@stanford.edu\r\nJoseph C. O’Brien\r\nStanford University\r\nStanford, USA\r\njobrien3@stanford.edu\r\nCarrie J. Cai\r\nGoogle Research\r\nMountain View, CA, USA\r\ncjcai@google.com\r\nMeredith Ringel Morris\r\nGoogle Research\r\nSeattle, WA, USA\r\nmerrie@google.com\r\nPercy Liang\r\nStanford University\r\nStanford, USA\r\npliang@cs.stanford.edu\r\nMichael S. Bernstein\r\nStanford University\r\nStanford, USA\r\nmsb@cs.stanford.edu\r\nFigure1:Generativeagentscreatebelievablesimulacraofhumanbehaviorforinteractiveapplications.Inthiswork,wedemon-\r\nstrate generative agents by populating a sandbox environment, reminiscent of The Sims, with twenty-five agents. Users can\r\nobserve and intervene as agents they plan their days, share news, form relationships, and coordinate group activities. ABSTRACT\r\nBelievable proxies of human behavior can empower interactive\r\napplications ranging from immersive environments to rehearsal\r\nspaces for interpersonal communication to prototyping tools. In\r\nthis paper, we introduce generative agents—computational software\r\nPermission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributed\r\nfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than the\r\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permission\r\nand/or a fee. Request permissions from permissions@acm.org.arXiv, April, 2023,\r\n©2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN xx-x-xxxx-xxxx-x/xx/xx. . . $15.00\r\nhttps://doi.org/xx.xx/xx.xx\r\nagents that simulate believable human behavior.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"0d67b29e-8102-4ca6-8395-48d1833eb818":{"id_":"0d67b29e-8102-4ca6-8395-48d1833eb818","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"AkyOzszqzzCLgoTx0mLXqNB85N11dXEcCP+hZnI6kCo=","metadata":{},"hash":"u35OMvcCoe3ropCtcREzPaB3C4WqhUCFBjI9cdRB21I="},"PREVIOUS":{"nodeId":"93da281a-1695-4b72-aa77-f6ea92bf2636","metadata":{},"hash":"CsoSlOAwk/CSQebkcH5eyIAX09H/8IBIrrakYGDzyNQ="}},"hash":"T2Wng9qC3yilHvpze05MI8Hcg3V9mhGaBkoB+4nUkFA=","text":"Generative agents\r\nwake up, cook breakfast, and head to work; artists paint, while\r\nauthors write; they form opinions, notice each other, and initiate\r\nconversations; they remember and reflect on days past as they plan\r\nthe next day. To enable generative agents, we describe an architec-\r\nture that extends a large language model to store a complete record\r\nof the agent’s experiences using natural language, synthesize those\r\nmemories over time into higher-level reflections, and retrieve them\r\ndynamically to plan behavior. We instantiate generative agents\r\nto populate an interactive sandbox environment inspired by The\r\nSims, where end users can interact with a small town of twenty five\r\nagents using natural language. In an evaluation, these generative\r\nagents produce believable individual and emergent social behav-\r\niors: for example, starting with only a single user-specified notion\r\narXiv:2304.03442v1  [cs.HC]  7 Apr 2023","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"a1064fd3-e074-467f-9a3b-6fd832115855":{"id_":"a1064fd3-e074-467f-9a3b-6fd832115855","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"MyfAAWxtnBRyjk7oDM+g/mW4zvxp2xfceqqkDURJyMc=","metadata":{},"hash":"GPmu6WNePPGwp0fGZF6riJ3eFAkV+9ktcqTgfByN0iQ="},"NEXT":{"nodeId":"c4b7a934-77a3-498f-944f-7f9973429d05","metadata":{},"hash":"3pHjSKqlBAKLi6H+PJvfF/jYF+W3QrX0J5DoyIWt4QM="}},"hash":"IVUq3eixqvtKNsDsUHbhLXGBW+d1lAgArHNGTQ4Bgd0=","text":"arXiv, April, 2023,J.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\r\nthat one agent wants to throw a Valentine’s Day party, the agents\r\nautonomously spread invitations to the party over the next two\r\ndays, make new acquaintances, ask each other out on dates to the\r\nparty, and coordinate to show up for the party together at the right\r\ntime. We demonstrate through ablation that the components of\r\nour agent architecture—observation, planning, and reflection—each\r\ncontribute critically to the believability of agent behavior. By fusing\r\nlarge language models with computational, interactive agents, this\r\nwork introduces architectural and interaction patterns for enabling\r\nbelievable simulations of human behavior. CCS CONCEPTS\r\n•Human-centeredcomputing→Interactivesystemsandtools;\r\n•Computing methodologies→Natural language processing. KEYWORDS\r\nHuman-AI Interaction, agents, generative AI, large language models\r\nACM Reference Format:\r\nJoon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel Morris,\r\nPercy Liang, and Michael S. Bernstein. 2023. Generative Agents: Interactive\r\nSimulacra of Human Behavior. In.ACM, New York, NY, USA, 22 pages. https://doi.org/xx.xx/xx.xx\r\n1  INTRODUCTION\r\nHow might we craft an interactive artificial society that reflects\r\nbelievable human behavior? From sandbox games such as The Sims\r\nto applications such as cognitive models [21] and virtual environ-\r\nments [9,58], for over four decades researchers and practitioners\r\nhave envisioned computational agents that can serve as believ-\r\nable proxies of human behavior. In these visions, computationally-\r\npowered agents act consistently with their past experiences and\r\nreact believably to their environments.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"c4b7a934-77a3-498f-944f-7f9973429d05":{"id_":"c4b7a934-77a3-498f-944f-7f9973429d05","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"MyfAAWxtnBRyjk7oDM+g/mW4zvxp2xfceqqkDURJyMc=","metadata":{},"hash":"GPmu6WNePPGwp0fGZF6riJ3eFAkV+9ktcqTgfByN0iQ="},"PREVIOUS":{"nodeId":"a1064fd3-e074-467f-9a3b-6fd832115855","metadata":{},"hash":"IVUq3eixqvtKNsDsUHbhLXGBW+d1lAgArHNGTQ4Bgd0="},"NEXT":{"nodeId":"9535bc3e-bfa0-489c-a205-38b3f77479b2","metadata":{},"hash":"kpvKgY4XofGvnMNHvbvCUVU0+4V0P564e/Hf9stRriQ="}},"hash":"3pHjSKqlBAKLi6H+PJvfF/jYF+W3QrX0J5DoyIWt4QM=","text":"Such simulations of human\r\nbehavior could populate virtual spaces and communities with real-\r\nistic social phenomena [26,79], train people how to handle rare yet\r\ndifficult interpersonal situations [43,51,93], test social science theo-\r\nries [11,45], craft model human processors for theory and usability\r\ntesting [21,38,50], power ubiquitous computing applications [30]\r\nand social robots [9,13], and underpin non-playable game charac-\r\nters [58,84] that can navigate complex human relationships in an\r\nopen world. However, the space of human behavior is vast and complex [84,\r\n108]. Despite striking progress in large language models [17] that\r\ncan simulate believable human behavior at a single time point [38,\r\n79], fully general agents that ensure long-term coherence would\r\nbe better suited by architectures that manage constantly-growing\r\nmemories as new interactions, conflicts, and events arise and fade\r\nover time, while handling cascading social dynamics that unfold\r\nbetween multiple agents. Success requires an approach that can\r\nretrieverelevant events and interactions over a long period,reflect\r\non those memories to generalize and draw higher-level inferences,\r\nand apply that reasoning to createplans and reactionsthat both\r\nmake sense in the moment and in the longer-term arc of the agent’s\r\nbehavior. In this paper, we introducegenerative agents—agents that draw\r\non generative models to simulate believable human behavior—and\r\ndemonstrate that they produce believable simulacra of both in-\r\ndividual and emergent group behavior. Generative agents draw\r\na wide variety of inferences about themselves, other agents, and\r\ntheir environment; they create daily plans that reflect their char-\r\nacteristics and experiences, act out those plans, react, and re-plan\r\nwhen appropriate; they respond when the end user changes their\r\nenvironment or commands them in natural language. For instance,\r\ngenerative agents turn off the stove when they see that their break-\r\nfast is burning, wait outside the bathroom if it is occupied, and\r\nstop to chat when they meet another agent they want to talk to. A society full of generative agents is marked by emergent social\r\ndynamics where new relationships are formed, information diffuses,\r\nand coordination arises across agents. To enable generative agents, we describe an agent architecture\r\nthat stores, synthesizes, and applies relevant memories to generate\r\nbelievable behavior using a large language model.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"9535bc3e-bfa0-489c-a205-38b3f77479b2":{"id_":"9535bc3e-bfa0-489c-a205-38b3f77479b2","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"MyfAAWxtnBRyjk7oDM+g/mW4zvxp2xfceqqkDURJyMc=","metadata":{},"hash":"GPmu6WNePPGwp0fGZF6riJ3eFAkV+9ktcqTgfByN0iQ="},"PREVIOUS":{"nodeId":"c4b7a934-77a3-498f-944f-7f9973429d05","metadata":{},"hash":"3pHjSKqlBAKLi6H+PJvfF/jYF+W3QrX0J5DoyIWt4QM="},"NEXT":{"nodeId":"a767ac4b-b4e7-4846-a4b4-e1bdcae202d5","metadata":{},"hash":"yp9euqbWo9cUfq4HsXvcq1IXv2XJj45xQnZu+d4wCIk="}},"hash":"kpvKgY4XofGvnMNHvbvCUVU0+4V0P564e/Hf9stRriQ=","text":"Our architecture\r\ncomprises three main components. The first is thememory stream,\r\na long-term memory module that records, in natural language, a\r\ncomprehensive list of the agent’s experiences. The retrieval model\r\ncombines relevance, recency, and importance to surface the records\r\nthat are needed to inform the agent’s moment-to-moment behavior. The second isreflection, which synthesizes memories into higher-\r\nlevel inferences over time, enabling the agent to draw conclusions\r\nabout itself and others to better guide its behavior. The third is\r\nplanning, which translates those conclusions and the current en-\r\nvironment into high-level action plans and then recursively into\r\ndetailed behaviors for action and reaction. These reflections and\r\nplans are fed back into the memory stream to influence the agent’s\r\nfuture behavior. This architecture suggests applications in multiple domains, from\r\nrole-play and social prototyping, to virtual worlds and games. In\r\nsocial role-play scenarios (e.g. interview preparation), a user could\r\nsafely rehearse difficult, conflict-laden conversations. When pro-\r\ntotyping social platforms, a designer could go beyond temporary\r\npersonas to prototype dynamic, complex interactions that unfold\r\nover time. For the purposes of this paper, we focus on the ability to\r\ncreate a small, interactive society of agents inspired by games such\r\nas The Sims.1By connecting our architecture to the ChatGPT large\r\nlanguage model [76], we manifest a small society of twenty five\r\nagents in a game environment. End users can observe and interact\r\nwith these agents. If an end user or developer wanted the town\r\nto host an in-game Valentine’s Day party, for example, traditional\r\ngame environments would require scripting tens of characters’ be-\r\nhavior manually. We demonstrate that, with generative agents, it\r\nis sufficient to simply tell one agent that she wants to throw a\r\nparty. Despite many potential points of failure—the party planner\r\nmust remember to tell other agents about the party, attendees must\r\nremember the invitation, those who remember must decide to ac-\r\ntually show up, and other possible points of failure—agents in our\r\nenvironment succeed. They spread the word about the party and\r\nthen show up, with one agent even asking another agent on a date\r\nto the party, all from this single user-generated seed suggestion.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"a767ac4b-b4e7-4846-a4b4-e1bdcae202d5":{"id_":"a767ac4b-b4e7-4846-a4b4-e1bdcae202d5","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"MyfAAWxtnBRyjk7oDM+g/mW4zvxp2xfceqqkDURJyMc=","metadata":{},"hash":"GPmu6WNePPGwp0fGZF6riJ3eFAkV+9ktcqTgfByN0iQ="},"PREVIOUS":{"nodeId":"9535bc3e-bfa0-489c-a205-38b3f77479b2","metadata":{},"hash":"kpvKgY4XofGvnMNHvbvCUVU0+4V0P564e/Hf9stRriQ="}},"hash":"yp9euqbWo9cUfq4HsXvcq1IXv2XJj45xQnZu+d4wCIk=","text":"We conducted two evaluations of generative agents: a controlled\r\nevaluation to test whether the agents produce believable individual\r\n1A demonstration of an actual simulation of the generative agent society can be viewed\r\nat the following link: https://reverie.herokuapp.com/arXiv_Demo/","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"c48a9238-c0a3-40ba-a6fa-066cca1a1f21":{"id_":"c48a9238-c0a3-40ba-a6fa-066cca1a1f21","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"L9UErMsvWeseZaQWN6TnfgR1vpTcU8iAj3LtRw7ov5Q=","metadata":{},"hash":"HY0aMZRr9eyQnoPXrFTXtjrser8ZtxijhvRrkLH1J9Y="},"NEXT":{"nodeId":"16be463e-e8c2-4ebe-8f89-3dbadedb244b","metadata":{},"hash":"xyeY7W74gJZkb6o7H+ZpXLWii9fVEYayecN4Qp01HVw="}},"hash":"r422GWkST39blT3qCpf6cRECTLW4Fr0J5cRgJFD7oFo=","text":"Generative AgentsarXiv, April, 2023,\r\nbehaviors in isolation, and an end-to-end evaluation where the\r\ngenerative agents interacted with each other in open-ended ways\r\nover two days of game time to understand their stability and emer-\r\ngent social behaviors. In the technical evaluation, we leverage a\r\nmethodological opportunity to evaluate an agent’s knowledge and\r\nbehavior by “interviewing” it in natural language to probe agents’\r\nability to stay in character, remember, plan, react, and reflect accu-\r\nrately. We compared several ablations that limit agents’ access to\r\nmemory, reflection, and planning. We observe that each of these\r\ncomponents is critical to strong performance across these inter-\r\nview tasks. Across the technical and the end-to-end evaluation, the\r\nmost common errors arose when the agent failed to retrieve rele-\r\nvant memories, fabricated embellishments to the agent’s memory,\r\nor inherited overly formal speech or behavior from the language\r\nmodel. In sum, this paper provides the following contributions:\r\n•Generative agents, believable simulacra of human behavior\r\nthat are dynamically conditioned on agents’ changing expe-\r\nriences and environment. •A novel architecture that makes it possible for generative\r\nagents to remember, retrieve, reflect, interact with other\r\nagents, and plan through dynamically evolving circumstances. The architecture leverages the powerful prompting capabili-\r\nties of large language models and supplements those capa-\r\nbilities to support longer-term agent coherence, the ability\r\nto manage dynamically-evolving memory, and recursively\r\nproduce more generations. •Two evaluations (a controlled evaluation and end-to-end\r\nevaluation) that establish causal effects of the importance\r\nof components of the architecture, as well as identify break-\r\ndowns arising from, e.g., improper memory retrieval. •Discussion of the opportunities and ethical and societal risks\r\nof generative agents in interactive systems. We argue that\r\nthese agents should be tuned to mitigate the risk of users\r\nforming parasocial relationships, logged to mitigate risks\r\nstemming from deepfakes and tailored persuasion, and ap-\r\nplied in ways that complement rather than replace human\r\nstakeholders in design processes. 2  RELATED WORK\r\nIn this section, we reflect on the prior literature in human-AI in-\r\nteraction and situate within its canon the agenda of building be-\r\nlievable proxies of human behavior.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"16be463e-e8c2-4ebe-8f89-3dbadedb244b":{"id_":"16be463e-e8c2-4ebe-8f89-3dbadedb244b","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"L9UErMsvWeseZaQWN6TnfgR1vpTcU8iAj3LtRw7ov5Q=","metadata":{},"hash":"HY0aMZRr9eyQnoPXrFTXtjrser8ZtxijhvRrkLH1J9Y="},"PREVIOUS":{"nodeId":"c48a9238-c0a3-40ba-a6fa-066cca1a1f21","metadata":{},"hash":"r422GWkST39blT3qCpf6cRECTLW4Fr0J5cRgJFD7oFo="},"NEXT":{"nodeId":"1ad3fe53-c793-4cc8-8c9d-9c8406229c76","metadata":{},"hash":"vYYpptLrxCg3ksLD0GOPp9blbZYiE2R1sKTgBVBhTjw="}},"hash":"xyeY7W74gJZkb6o7H+ZpXLWii9fVEYayecN4Qp01HVw=","text":"This agenda, once hailed as a\r\nnorth star in interaction, game, and artificial intelligence communi-\r\nties [9,58,84,85], has remained challenging due to the complexity\r\nof human behavior [16,108]. We synthesize this research to suggest\r\nthat large language models, though not sufficient by themselves,\r\nopen up a new angle for creating believable agents when leveraged\r\nusing the appropriate architecture. 2.1  Human-AI Interaction\r\nInteractive artificial intelligence systems aim to combine human in-\r\nsights and capabilities in computational artifacts that can augment\r\ntheir users [3,29]. A long line of work has explored ways to allow\r\nusers to interactively specify model behavior. For instance, Crayons\r\ndemonstrated an early vision of interactive machine learning, allow-\r\ning non-expert users to train classifiers [29]. Further work helped to\r\narticulate how end users might describe their classification goals to\r\nthe system through examples [33] and/or demonstration [31]. More\r\nrecent work has extended these explorations to deep learning [62]\r\nand prompt-based authoring [49, 66, 106]. Meanwhile, a persistent thread of research has advanced the case\r\nfor language- and agent-based interaction in human-computer in-\r\nteraction. Formative work such as SHRDLU [103] and ELIZA [102]\r\ndemonstrated the opportunity and the risks of natural language\r\ninteraction with computing systems. As research progressed, it\r\nbecame clear that autonomous agents could offer new metaphors\r\nfor delegation and interaction [67], but the delegation lines be-\r\ntween humans and agents have continued to be debated and refined\r\n[46,88,89]. Recently, this technology has become stable enough\r\nthat it has become possible for agents to interact via natural lan-\r\nguage in large and complex online social environments (e.g., [54]). Natural language interaction offers a novel modality that can ex-\r\ntend user abilities in domains such as photo editing [2,34,64] and\r\ncode editing [87]. We convene these threads of work to show that we can now\r\ncreate agents that proxy human behavior for interactive systems,\r\nand  interact  with  them  via  natural  language.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"1ad3fe53-c793-4cc8-8c9d-9c8406229c76":{"id_":"1ad3fe53-c793-4cc8-8c9d-9c8406229c76","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"L9UErMsvWeseZaQWN6TnfgR1vpTcU8iAj3LtRw7ov5Q=","metadata":{},"hash":"HY0aMZRr9eyQnoPXrFTXtjrser8ZtxijhvRrkLH1J9Y="},"PREVIOUS":{"nodeId":"16be463e-e8c2-4ebe-8f89-3dbadedb244b","metadata":{},"hash":"xyeY7W74gJZkb6o7H+ZpXLWii9fVEYayecN4Qp01HVw="}},"hash":"vYYpptLrxCg3ksLD0GOPp9blbZYiE2R1sKTgBVBhTjw=","text":"In  doing  so,  this\r\nwork re-opens the door to examining foundational HCI questions\r\naround cognitive models such as GOMS and KLM [21,22], around\r\nprototyping tools [79], and around ubiquitous computing applica-\r\ntions [25, 30, 100]. 2.2  Believable Proxies of Human Behavior\r\nPrior literature has describedbelievability, orbelievable agents, as a\r\ncentral design and engineering goal. Believable agents are designed\r\nto provide an illusion of life and present a facade of realism in the\r\nway they appear to make decisions and act on their own volition,\r\nsimilar to the characters in Disney movies [9,95]. These agents can\r\npopulate and perceive an open-world environment like the one we\r\ninhabit [9,58], and strive to behave in ways that exhibit emergent\r\nbehaviors grounded in social interactions with users or other agents\r\nwith the aim of becoming believable proxies of our behavior in hy-\r\npothetical simulations of individuals and communities [19,35,70]. Historically, these agents were developed in the context of intelli-\r\ngent game NPCs [58,84]. Creating NPCs with believable behavior,\r\nif possible, could enhance player experiences in games and inter-\r\nactive fictions by enabling emergent narratives [7,15,48,92] and\r\nsocial interactions with the agents [110]. However, more impor-\r\ntantly, game worlds provide increasingly realistic representations\r\nof real-world affordances, and as observed by Laird and van Lent in\r\n2001, these simulated worlds offer accessible testbeds for develop-\r\ners of believable agents to finesse the agents’ cognitive capabilities\r\nwithout worrying about implementing robotics in the real world\r\nor creating simulation environments from scratch [58, 84]. A diverse set of approaches to creating believable agents emerged\r\nover the past four decades. In implementation, however, these ap-\r\nproaches often simplified the environment or dimensions of agent\r\nbehavior to make the effort more manageable [16,72]. Rule-based\r\napproaches, such as finite-state machines [90,96] and behavior","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"10a0149c-bc90-4a9a-9f02-0291a62509ef":{"id_":"10a0149c-bc90-4a9a-9f02-0291a62509ef","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"S6W+EbA9Eu4yT7ytiKKcJrluiVHyKA+bIpfaU37q8yM=","metadata":{},"hash":"7hGR1MXP8FKWKLOVsuvDxRpZnDExmAMtLxlI8OZLLn0="},"NEXT":{"nodeId":"ed3bc9e3-dc83-4e19-ac76-99ac9c4bf2e5","metadata":{},"hash":"hMXrohI5mb5cjVdG2tJC8kW5KXcVYdvTA2Y3Cx/JcR8="}},"hash":"8ZthI6Aie9jSoLIP0QC0bgD1yJnKTp7lzgXlL9jA+1Q=","text":"arXiv, April, 2023,J.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\r\ntrees [40,53,81], account for the brute force approach of human-\r\nauthoring the agent’s behavior [70]. They provide a straightforward\r\nway of creating simple agents that is still the most dominant ap-\r\nproach today [68,73,109], and can even handle rudimentary social\r\ninteractions, as shown in simulation games such as Mass Effect [12]\r\nand The Sims [6] series. Nonetheless, manually crafting behavior\r\nthat can comprehensively address the breadth of possible interac-\r\ntions in an open world is untenable. This means that the resulting\r\nagent behaviors may not fully represent the consequences of their\r\ninteractions [69–71], and cannot perform new procedures that were\r\nnot hard-coded in their script [90,96]. On the other hand, preva-\r\nlent learning-based approaches for creating believable agents, such\r\nas reinforcement learning, have overcome the challenge of man-\r\nual authoring by letting the agents learn their behavior, and have\r\nachieved superhuman performance in recent years in games such\r\nas AlphaStar for Starcraft [98] and OpenAI Five for Dota 2 [10]. However, their success has largely taken place in adversarial games\r\nwith readily definable rewards that a learning algorithm can op-\r\ntimize for. They have not yet addressed the challenge of creating\r\nbelievable agents in an open world [39, 73, 90]. Cognitive architectures in computation, pioneered by Newell,\r\naimed to build the infrastructure for supporting a comprehensive\r\nset of cognitive functions [75] that suited the all-encompassing\r\nnature of believable agents held in its original vision. They fueled\r\nsome of the earliest examples of believable agents. For instance,\r\nQuakebot-SOAR [59] and ICARUS [24,63] generated NPCs in first-\r\nperson shooter games, while TacAir-SOAR [80] generated pilots in\r\naerial combat training simulations.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"ed3bc9e3-dc83-4e19-ac76-99ac9c4bf2e5":{"id_":"ed3bc9e3-dc83-4e19-ac76-99ac9c4bf2e5","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"S6W+EbA9Eu4yT7ytiKKcJrluiVHyKA+bIpfaU37q8yM=","metadata":{},"hash":"7hGR1MXP8FKWKLOVsuvDxRpZnDExmAMtLxlI8OZLLn0="},"PREVIOUS":{"nodeId":"10a0149c-bc90-4a9a-9f02-0291a62509ef","metadata":{},"hash":"8ZthI6Aie9jSoLIP0QC0bgD1yJnKTp7lzgXlL9jA+1Q="},"NEXT":{"nodeId":"f8113839-51f3-4e73-b4ed-9c76d9949786","metadata":{},"hash":"LNPqpdhzZF3hFmfUPVi/pI5g/FYFOad4eNuXq7nHae4="}},"hash":"hMXrohI5mb5cjVdG2tJC8kW5KXcVYdvTA2Y3Cx/JcR8=","text":"The architectures used by these\r\nagents differed (Quakebot- and TacAir-SOAR relied on SOAR [60],\r\nwhile ICARUS relied on its own variation that was inspired by\r\nSOAR and ACT-R [5]), but they shared the same underlying prin-\r\nciple [61]. They maintained short-term and long-term memories,\r\nfilled these memories with symbolic structures, and operated in\r\nperceive-plan-act cycles, dynamically perceiving the environment\r\nand matching it with one of the manually crafted action proce-\r\ndures [57,96]. Agents created using cognitive architectures aimed\r\nto be generalizable to most, if not all, open-world contexts and\r\nexhibited robust behavior for their time. However, their space of\r\naction was limited to manually crafted procedural knowledge, and\r\nthey did not offer a mechanism through which the agents could be\r\ninspired to seek new behavior. As such, these agents were deployed\r\nmostly in non-open-world contexts such as first-person shooter\r\ngames [24, 59] or blocks worlds [63]. Today, creating believable agents as described in its original\r\ndefinition remains an open problem [84,108]. Many have moved on,\r\narguing that although existing approaches for creating believable\r\nagents might be cumbersome and limited, they are good enough\r\nto support existing gameplay and interactions [23,74,108]. Our\r\nargument is that large language models offer an opportunity to\r\nre-examine these questions, provided that we can craft an effective\r\narchitecture to synthesize memories into believable behavior. We\r\noffer a step toward such an architecture in this paper. 2.3  Large Language Models and Human\r\nBehavior\r\nGenerative agents leverage a large language model to power their\r\nbehavior. The key observation is that large language models en-\r\ncode a wide range of human behavior represented in their training\r\ndata [14,17]. If prompted with a narrowly defined context, the\r\nmodels can be used to generate believable behavior. Recent work\r\nhas demonstrated the efficacy of this approach. For instance, Social\r\nSimulacra used a large language model to generate users that would\r\npopulate new social computing systems to prototype their emergent\r\nsocial dynamics [79]. This approach used a prompt chain [105,106]\r\nto generate short natural language descriptions of personas and\r\ntheir behaviors as they appear in the system being prototyped.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"f8113839-51f3-4e73-b4ed-9c76d9949786":{"id_":"f8113839-51f3-4e73-b4ed-9c76d9949786","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"S6W+EbA9Eu4yT7ytiKKcJrluiVHyKA+bIpfaU37q8yM=","metadata":{},"hash":"7hGR1MXP8FKWKLOVsuvDxRpZnDExmAMtLxlI8OZLLn0="},"PREVIOUS":{"nodeId":"ed3bc9e3-dc83-4e19-ac76-99ac9c4bf2e5","metadata":{},"hash":"hMXrohI5mb5cjVdG2tJC8kW5KXcVYdvTA2Y3Cx/JcR8="},"NEXT":{"nodeId":"efc3082b-064d-48b5-bcaf-a9121166cf21","metadata":{},"hash":"bj9kDmVWpASDbsRZrdaLUtp/YQ364x/0fOSF/qjAIGk="}},"hash":"LNPqpdhzZF3hFmfUPVi/pI5g/FYFOad4eNuXq7nHae4=","text":"Other empirical studies have replicated existing social science stud-\r\nies [45], political surveys [91], and generated synthetic data [38]. Large language models have also been used to generate interactive\r\nhuman behavior for users to engage with. In gaming, for instance,\r\nthese models have been employed to create interactive fiction [36]\r\nand text adventure games [20]. With their ability to generate and\r\ndecompose action sequences, large language models have also been\r\nused in planning robotics tasks [47]. For example, when presented\r\nwith a task, such as picking up a bottle, the model is prompted to\r\nbreak down the task into smaller action sequences, such as heading\r\nto the table where the bottle is located and picking it up. We posit that, based on the work summarized above, large lan-\r\nguage models can become a key ingredient for creating believable\r\nagents. The existing literature largely relies on what could be con-\r\nsidered first-order templates that employ few-shot prompts [37,65]\r\nor chain-of-thought prompts [99]. These templates are effective in\r\ngenerating behavior that is conditioned solely on the agent’s cur-\r\nrent environment (e.g., how would a troll respond to a given post,\r\nwhat actions would a robot need to take to enter a room given that\r\nthere is a door). However, believable agents require conditioning\r\nnot only on their current environment but also on a vast amount\r\nof past experience, which is a poor fit (and as of today, impossi-\r\nble due to the underlying models’ limited context window) using\r\nfirst-order prompting. Recent studies have attempted to go beyond\r\nfirst-order prompting by augmenting language models with a static\r\nknowledge base and an information retrieval scheme [52] or with\r\na simple summarization scheme [104]. This paper extends these\r\nideas to craft an agent architecture that handles retrieval where\r\npast experience is dynamically updated at each time step and mixed\r\nwith agents’ current context and plans, which may either reinforce\r\nor contradict each other. 3  GENERATIVE AGENT BEHAVIOR AND\r\nINTERACTION\r\nTo make concrete the affordances of generative agents, we instanti-\r\nate them as characters in a simple sandbox world reminiscent of\r\nThe Sims [6]. This sprite-based sandbox game world, Smallville,\r\nevokes a small town environment.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"efc3082b-064d-48b5-bcaf-a9121166cf21":{"id_":"efc3082b-064d-48b5-bcaf-a9121166cf21","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"S6W+EbA9Eu4yT7ytiKKcJrluiVHyKA+bIpfaU37q8yM=","metadata":{},"hash":"7hGR1MXP8FKWKLOVsuvDxRpZnDExmAMtLxlI8OZLLn0="},"PREVIOUS":{"nodeId":"f8113839-51f3-4e73-b4ed-9c76d9949786","metadata":{},"hash":"LNPqpdhzZF3hFmfUPVi/pI5g/FYFOad4eNuXq7nHae4="}},"hash":"bj9kDmVWpASDbsRZrdaLUtp/YQ364x/0fOSF/qjAIGk=","text":"This sprite-based sandbox game world, Smallville,\r\nevokes a small town environment. In this section, we walk through\r\nthe affordances and interactions with generative agents in Small-\r\nville, and describe how the agents behave in it. Then, in Section 4,\r\nwe introduce our generative agent architecture that powers these\r\naffordances and interactions. In Section 5, we describe the sandbox","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"a3b7b913-9ee1-486e-80d1-aa8b86f90a84":{"id_":"a3b7b913-9ee1-486e-80d1-aa8b86f90a84","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Dzl6U1CCT0a+IobnJGOu5NQDApgIBiKpOTXTuTjCf+c=","metadata":{},"hash":"M1cq3opUTptEcOeIJe/bc9msYPmnueU6A/c7UCJ7z3E="},"NEXT":{"nodeId":"e482e56c-8510-40ef-95fe-9085f9460811","metadata":{},"hash":"3jD2asClBgif6vz+2tfYFxM1oozGyL4k12rUmR/BuEY="}},"hash":"R1A1YOqNkz4yLi5gDISH5Wp3NEKMnV6u6NPmDUAG2UE=","text":"Generative AgentsarXiv, April, 2023,\r\nFigure 2: The Smallville sandbox world, with areas labeled. The root node describes the entire world, children describe areas\r\n(e.g., houses, cafe, stores), and leaf nodes describe objects (e.g., table, bookshelf). Agent remember a subgraph reflecting the\r\nparts of the world they have seen, in the state that they saw them. environment implementation and how the agents interact with the\r\nsandbox world’s underlying engine. 3.1  Agent Avatar and Communication\r\nA community of 25 unique agents inhabit Smallville. Each agent is\r\nrepresented by a simple sprite avatar. We authored one paragraph\r\nof natural language description to depict each agent’s identity,\r\nincluding their occupation and relationship with other agents, as\r\nseed memories. For example, John Lin has the following description:\r\nJohn Lin is a pharmacy shopkeeper at the Willow\r\nMarket and Pharmacy who loves to help people. He\r\nis always looking for ways to make the process\r\nof getting medication easier for his customers;\r\nJohn Lin is living with his wife, Mei Lin, who\r\nis a college professor, and son, Eddy Lin, who is\r\na student studying music theory; John Lin loves\r\nhis family very much; John Lin has known the old\r\ncouple next-door, Sam Moore and Jennifer Moore,\r\nfor a few years; John Lin thinks Sam Moore is a\r\nkind and nice man; John Lin knows his neighbor,\r\nYuriko  Yamamoto,  well;  John  Lin  knows  of  his\r\nneighbors, Tamara Taylor and Carmen Ortiz, but\r\nhas not met them before; John Lin and Tom Moreno\r\nare colleagues at The Willows Market and Pharmacy;\r\nJohn Lin and Tom Moreno are friends and like to\r\ndiscuss local politics together; John Lin knows\r\nthe Moreno family somewhat well — the husband Tom\r\nMoreno and the wife Jane Moreno. Each semicolon-delimited phrase is entered into the agent’s initial\r\nmemory as memories at the start of the simulation. 3.1.1    Inter-Agent Communication.The agents interact with the\r\nworld by their actions, and with each other through natural lan-\r\nguage.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"e482e56c-8510-40ef-95fe-9085f9460811":{"id_":"e482e56c-8510-40ef-95fe-9085f9460811","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Dzl6U1CCT0a+IobnJGOu5NQDApgIBiKpOTXTuTjCf+c=","metadata":{},"hash":"M1cq3opUTptEcOeIJe/bc9msYPmnueU6A/c7UCJ7z3E="},"PREVIOUS":{"nodeId":"a3b7b913-9ee1-486e-80d1-aa8b86f90a84","metadata":{},"hash":"R1A1YOqNkz4yLi5gDISH5Wp3NEKMnV6u6NPmDUAG2UE="}},"hash":"3jD2asClBgif6vz+2tfYFxM1oozGyL4k12rUmR/BuEY=","text":"At each time step of the sandbox engine, the agents output a\r\nnatural language statement describing their current action, such as\r\n\"Isabella Rodriguez is writing in her journal\", \"Isabella Rodriguez is\r\nchecking her emails\", \"Isabella Rodriguez is talking with her family\r\non the phone\", or \"Isabella Rodriguez is getting ready for bed\". This\r\nstatement is then translated into concrete movements that affect the\r\nsandbox world. The action is displayed on the sandbox interface as\r\na set of emojis that provide an abstract representation of the action\r\nin the overhead view. To accomplish this, the system employs a\r\nlanguage model that translates the action into a set of emojis, which\r\nappear above each avatar in a speech bubble. For example, \"Isabella\r\nRodriguez is writing in her journal\" is displayed as, while\r\n\"Isabella Rodriguez is checking her emails\" appears as. The\r\nfull natural language description of the action can be accessed by\r\nclicking on the agent avatar. Agents communicate with each other in full natural language. Agents are aware of other agents in their local area, and the genera-\r\ntive agent architecture determines whether they walk by or engage\r\nin conversation. Here, a sample in the middle of a conversation\r\nbetween the agents Isabella Rodriguez and Tom Moreno about the\r\nupcoming election:2\r\nIsabella:  I’m  still  weighing  my  options,  but  I’ve  been\r\ndiscussing the election with Sam Moore. What are your\r\nthoughts on him? Tom: To be honest, I don’t like Sam Moore. I think he’s\r\nout of touch with the community and doesn’t have our\r\nbest interests at heart. 2We note that the conversational style of these agents can fe el overly formal, likely a\r\nresult of instruction tuning in the underlying models. We expect that writing stylewill be better controllable in future language models.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"2625c28a-28de-4a08-95b3-02548e103a3c":{"id_":"2625c28a-28de-4a08-95b3-02548e103a3c","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"HfjknuCqoxme2LyfzNMZRV6qX1KBg20TFC5nLGWHTZg=","metadata":{},"hash":"f8uliaLWs8xIeVrZfR5Bns4RsE65VaF/SuvnX84eEwM="},"NEXT":{"nodeId":"c60847c9-0b8e-4ff9-b1a2-5963f8a83a3c","metadata":{},"hash":"/SrbT8eKfjyr+fwSVAKmZx4FPO0P4vhrG6/0fdrdL/w="}},"hash":"L4mfncSockRGXt/OquPIMUoodtClvUoJb1Cfen9ikqo=","text":"arXiv, April, 2023,J.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\r\n3.1.2    User Controls.A user running this simulation can steer the\r\nsimulation and intervene, either by communicating with the agent\r\nthrough conversation, or by issuing a directive to an agent in the\r\nform of an ‘inner voice’. The user communicates with the agent through natural language,\r\nby specifying a persona that the agent should perceive them as. For\r\nexample, if the user specifies that they are a news “reporter” and\r\nasks about the upcoming election, “Who is running for office?”, the\r\nJohn agent replies:\r\nJohn: My friends Yuriko, Tom and I have been talking\r\nabout the upcoming election and discussing the candi-\r\ndate Sam Moore. We have all agreed to vote for him\r\nbecause we like his platform. To directly command one of the agents, the user takes on the per-\r\nsona of the agent’s “inner voice”—this makes the agent more likely\r\nto treat the statement as a directive. For instance, when told “You\r\nare going to run against Sam in the upcoming election” by a user\r\nas John’s inner voice, John decides to run in the election and shares\r\nhis candidacy with his wife and son. 3.2  Environmental Interaction\r\nSmallville features the common affordances of a small village in-\r\ncluding a cafe, bar, park, school, dorm, houses, and stores. It also\r\ndefines subareas and objects that make those spaces functional,\r\nsuch as a kitchen in a house and a stove in the kitchen (Figure 2). All spaces serving as agents’ primary living quarters feature a bed,\r\ndesk, closet, shelf, as well as a bathroom and a kitchen.3\r\nAgents move around Smallville as one would in a simple video\r\ngame, entering and leaving buildings, navigating its map, and ap-\r\nproaching other agents. Agent movements are directed by the gen-\r\nerative agent architecture and the sandbox game engine: when the\r\nmodel dictates that the agent will move to a location, we calculate\r\na walking path to the destination in the Smallville environment\r\nand the agent begins moving. In addition, users can also enter the\r\nsandbox world of Smallville as an agent operating within it.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"c60847c9-0b8e-4ff9-b1a2-5963f8a83a3c":{"id_":"c60847c9-0b8e-4ff9-b1a2-5963f8a83a3c","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"HfjknuCqoxme2LyfzNMZRV6qX1KBg20TFC5nLGWHTZg=","metadata":{},"hash":"f8uliaLWs8xIeVrZfR5Bns4RsE65VaF/SuvnX84eEwM="},"PREVIOUS":{"nodeId":"2625c28a-28de-4a08-95b3-02548e103a3c","metadata":{},"hash":"L4mfncSockRGXt/OquPIMUoodtClvUoJb1Cfen9ikqo="},"NEXT":{"nodeId":"388c054b-bfe4-4233-925d-9e1f2379aac0","metadata":{},"hash":"IOmxApv8QW3qkJxglxfUkCKNRAHS2/P14hNSUc0m/s8="}},"hash":"/SrbT8eKfjyr+fwSVAKmZx4FPO0P4vhrG6/0fdrdL/w=","text":"The\r\nagent that the user embodies can be an agent already present in\r\nthe world, such as Isabella and John, or it can be an outside visitor\r\nwith no prior history in Smallville. The inhabitants of Smallville\r\nwill treat the user-controlled agent no differently than they treat\r\neach other. They recognize its presence, initiate interactions, and\r\nremember its behavior before forming opinions about it. Users and agents can influence the state of the objects in this\r\nworld, much like in sandbox games such as The Sims. For example,\r\na bed can be occupied when an agent is sleeping, and a refrigerator\r\ncan be empty when an agent uses up the ingredients to make\r\nbreakfast. End users can also reshape an agent’s environment in\r\nSmallville by rewriting the status of objects surrounding the agent\r\nin natural language. For instance, when Isabella is making breakfast\r\nin the morning, the user can change the status of the kitchen stove\r\nfrom “turned on” to “burning” by inputting a command to the\r\nsystem that chooses the object and illustrates its new status, like\r\nthis: “<Isabella’s apartment: kitchen: stove> is burning. ” Isabella\r\nwill notice this in the next moment and go to turn off the stove\r\n3This environment design is not the focus of our work, so we generate this environment\r\nmanually, not automatically. Future work can continue to expand the richness of theagents’ environments. and remake her breakfast. Likewise, if the user sets the status of\r\nIsabella’s shower to “leaking water” when she enters the bathroom,\r\nshe gathers tools from her living room and try to fix the leak. 3.3  Example “Day in the Life”\r\nStarting from the single-paragraph description, agents begin plan\r\ntheir days. As time passes in the sandbox world, their behaviors\r\nevolve as these agents interact with each other and the world, build\r\nmemories and relationships, and coordinate joint activities. We demonstrate the behavior of generative agents by tracing the\r\noutput of our system over the course of one day for the agent John\r\nLin (Figure 3). In the Lin family, John is the first to wake up at 7 a.m. He brushes his teeth, takes a shower, gets dressed, eats breakfast,\r\nand checks the news at the dining table in the living room.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"388c054b-bfe4-4233-925d-9e1f2379aac0":{"id_":"388c054b-bfe4-4233-925d-9e1f2379aac0","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"HfjknuCqoxme2LyfzNMZRV6qX1KBg20TFC5nLGWHTZg=","metadata":{},"hash":"f8uliaLWs8xIeVrZfR5Bns4RsE65VaF/SuvnX84eEwM="},"PREVIOUS":{"nodeId":"c60847c9-0b8e-4ff9-b1a2-5963f8a83a3c","metadata":{},"hash":"/SrbT8eKfjyr+fwSVAKmZx4FPO0P4vhrG6/0fdrdL/w="}},"hash":"IOmxApv8QW3qkJxglxfUkCKNRAHS2/P14hNSUc0m/s8=","text":"At 8\r\na.m., Eddy follows suit, rushing out of bed to prepare for his classes. He catches up with John just as he is about to head out:\r\nJohn: Good morning Eddy. Did you sleep well? Eddy: Good morning dad. Yeah, I slept great. John: That’s good. What are you working on today? Eddy: I’m working on a new music composition for my\r\nclass. It’s due this week, so I’m trying to get it finished. But I’m having so much fun with it! John: That sounds great! Soon after Eddy heads out, Mei wakes up and joins John. Mei asks\r\nabout her son, and John recalls the conversation that they just had:\r\nMei: Did Eddy already leave for school? John: Yes, he just left. He’s working on a music com-\r\nposition for his class. Mei: Oh, that’s wonderful! Tell me about it. John: I think he’s really enjoying it! He said he’s having\r\na lot of fun with it. Mei: That’s great! I’m so proud of him. As they finish their conversation, Mei and John pack up. Mei goes\r\non to teach and work on her research paper, while John opens his\r\npharmacy counter at the Willow Market and Pharmacy by 9 a.m. 3.4  Emergent Social Behaviors\r\nBy interacting with each other, generative agents in Smallville\r\nexchange information, form new relationships, and coordinate joint\r\nactivities. Extending prior work [79], these social behaviors are\r\nemergent rather than pre-programmed. 3.4.1    Information Diffusion.As agents notice each other, they may\r\nengage in dialogue—as they do so, information can spread from\r\nagent to agent. For instance, in a conversation between Sam and\r\nTom at the grocery store, Sam tells Tom about his candidacy in the\r\nlocal election:\r\nSam: Hey Tom, how’s it going? Tom: Good, thanks. What’s up? Sam: Well, I wanted to talk to you about something. I’m\r\nactually running for mayor in the upcoming local elec-\r\ntion. Tom: Really? That’s great news! Why are you running? Sam: I’ve been involved in local politics for years now,","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"0ce8815f-c830-4547-853d-be8a8ef3b0e9":{"id_":"0ce8815f-c830-4547-853d-be8a8ef3b0e9","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"cNDKdauWwKVRmdPpztkwy2OjIM/qGx/zNE1apv+f9PY=","metadata":{},"hash":"khYvTXoriz6Yl8YJ7iMcATM8G0maUO1OatHW8UlmYxc="},"NEXT":{"nodeId":"674b815f-8b3b-456a-8cc1-74a9651c9864","metadata":{},"hash":"AYYy0TZFKWqqj0l7eUM1yhtu71V2fXUiYYVs0BsmqV8="}},"hash":"biNw+CFGzaqSWR5D5f0xN3+ln7qsmBuFZQvY+URAeGE=","text":"Generative AgentsarXiv, April, 2023,\r\nFigure 3: A morning in the life of a generative agent, John Lin. John wakes up around 6 am and completes his morning routine,\r\nwhich includes brushing his teeth, taking a shower, and eating breakfast. He briefly catches up with his wife, Mei, and son,\r\nEddy, before heading out to begin his workday. Figure 4: At the beginning of the simulation, one agent is ini-\r\ntialized with an intent to organize a Valentine’s Day party. Despite many possible points of failure in the ensuring\r\nchain of events—agents might not act on that intent, might\r\nnot remember to tell others, might not remember to show\r\nup—the Valentine’s Day party does in fact occur, with a num-\r\nber of agents gathering and interacting. and I really feel like I can make a difference in our com-\r\nmunity. Plus, I want to bring new ideas and perspec-\r\ntives to the table. Later that day, after Sam left, Tom and John, who heard the news\r\nfrom another source, discuss Sam’s chances of winning the election:\r\nJohn: I heard that Sam Moore is running for mayor in\r\nthe local election. Do you think he has a good chance\r\nof winning? Tom: I do think he has a good chance. He’s been work-\r\ning hard in the community and I think he will get a lot of\r\nsupport. What do you think? John: I think it’s great that he’s running. I’m curious to\r\nsee who else is running and how the election will turn\r\nout. Gradually, Sam’s candidacy becomes the talk of the town, with\r\nsome supporting him and others remaining undecided. 3.4.2    Relationship memory.Agents in Smallville form new rela-\r\ntionships over time, and remember their interactions with other\r\nagents. For example, Sam does not know Latoya Williams at the\r\nstart. While taking a walk in Johnson Park, Sam runs into Latoya,\r\nand they introduce themselves and Latoya mentions that she is\r\nworking on a photography project:“I’m here to take some photos\r\nfor a project I’m working on.”In a later interaction, Sam’s interac-\r\ntions with Latoya indicate a memory of that interaction, as he asks\r\n“Hi, Latoya.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"674b815f-8b3b-456a-8cc1-74a9651c9864":{"id_":"674b815f-8b3b-456a-8cc1-74a9651c9864","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"cNDKdauWwKVRmdPpztkwy2OjIM/qGx/zNE1apv+f9PY=","metadata":{},"hash":"khYvTXoriz6Yl8YJ7iMcATM8G0maUO1OatHW8UlmYxc="},"PREVIOUS":{"nodeId":"0ce8815f-c830-4547-853d-be8a8ef3b0e9","metadata":{},"hash":"biNw+CFGzaqSWR5D5f0xN3+ln7qsmBuFZQvY+URAeGE="}},"hash":"AYYy0TZFKWqqj0l7eUM1yhtu71V2fXUiYYVs0BsmqV8=","text":"How is your project going?”and she replies“Hi, Sam. It’s\r\ngoing well! ”\r\n3.4.3    Coordination.Generative agents coordinate with each other. Isabella Rodriguez, at Hobbs Cafe, is initialized with an intent to\r\nplan a Valentine’s Day party from 5 to 7 p.m. on February 14th. From\r\nthis seed, the agent proceeds to invites friends and customers when\r\nshe sees them at Hobbs Cafe or elsewhere. Isabella then spends the\r\nafternoon of the 13th decorating the cafe for the occasion. Maria, a\r\nfrequent customer and close friend of Isabella’s, arrives at the cafe. Isabella asks for Maria’s help in decorating for the party, and Maria\r\nagrees. Maria’s character description mentions that she has a crush\r\non Klaus. That night, Maria invites Klaus, her secret crush, to join\r\nher at the party, and he gladly accepts. On Valentine’s Day, five agents—including Klaus and Maria—\r\nshow up at Hobbs Cafe at 5pm and they enjoy the festivities (Fig-\r\nure 4). In this scenario, the end user only set Isabella’s initial intent","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"6295984c-a200-43e4-98be-9aaf83665415":{"id_":"6295984c-a200-43e4-98be-9aaf83665415","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"PAIRJZP0Dy5Xllq1oDxdyUjauVOFt5cKyD3HW5Xb/cM=","metadata":{},"hash":"+QBnViBi3B+/kvoIm/DeDlBR0tS4PkzHV1tI58jau5g="},"NEXT":{"nodeId":"474cf858-55d5-4f43-8cec-a27d51609a03","metadata":{},"hash":"XfFOquui4F6Maul0GFUNozMjDlav3+w5mebh263Hddo="}},"hash":"vIXXGV2QmtaCHJQ8m62CqeETQII/mc88j1wyZmcROcU=","text":"arXiv, April, 2023,J.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\r\nFigure 5: Our generative agent architecture. Agents perceive their environment, and all perceptions are saved in a compre-\r\nhensive record of the agent’s experiences called the memory stream. Based on their perceptions, the architecture retrieves\r\nrelevant memories, then uses those retrieved actions to determine an action. These retrieved memories are also used to form\r\nlonger-term plans, and to create higher-level reflections, which are both entered into the memory stream for future use. to throw a party and Maria’s crush on Klaus: the social behaviors\r\nof spreading the word, decorating, asking each other out, arriving\r\nat the party, and interacting with each other at the party, were\r\ninitiated by the agent architecture. 4  GENERATIVE AGENT ARCHITECTURE\r\nGenerative agents aim to provide a framework for behavior in an\r\nopen world: one that can engage in interactions with other agents\r\nand can react to changes in the environment. Generative agents\r\ntake their current environment and past experience as input and\r\ngenerate behavior as output. Underlying this behavior is a novel\r\nagent architecture that combines a large language model with mech-\r\nanisms for synthesizing and retrieving relevant information to con-\r\ndition the language model’s output on. Without these mechanisms,\r\nlarge language models can output behavior, but the resulting agents\r\nmay not react based on the agent’s past experiences, may not make\r\nimportant inferences, and may not maintain long-term coherence. Challenges with long-term planning and coherence remain [18]\r\neven with today’s most performant models such as GPT-4. Because\r\ngenerative agents produce large streams of events and memories\r\nthat must be retained, a core challenge of our architecture is to\r\nensure that the most relevant pieces of the agent’s memory are\r\nretrieved and synthesized when needed. At the center of our architecture is the memory stream, a data-\r\nbase that maintains a comprehensive record of an agent’s experi-\r\nence. From the memory stream, records are retrieved as relevant\r\nto plan the agent’s actions and react appropriately to the environ-\r\nment, and records are recursively synthesized into higher- and\r\nhigher-level observations that guide behavior.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"474cf858-55d5-4f43-8cec-a27d51609a03":{"id_":"474cf858-55d5-4f43-8cec-a27d51609a03","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"PAIRJZP0Dy5Xllq1oDxdyUjauVOFt5cKyD3HW5Xb/cM=","metadata":{},"hash":"+QBnViBi3B+/kvoIm/DeDlBR0tS4PkzHV1tI58jau5g="},"PREVIOUS":{"nodeId":"6295984c-a200-43e4-98be-9aaf83665415","metadata":{},"hash":"vIXXGV2QmtaCHJQ8m62CqeETQII/mc88j1wyZmcROcU="},"NEXT":{"nodeId":"f57bc90f-c6df-483d-95ed-fa37c277573d","metadata":{},"hash":"+e0Jx6fgQ+BHjySCjyHllPxopwBk+CEvh9MRcwd5BjY="}},"hash":"XfFOquui4F6Maul0GFUNozMjDlav3+w5mebh263Hddo=","text":"Everything in the\r\narchitecture is recorded and reasoned over as natural language\r\ndescription, allowing the architecture to leverage a large language\r\nmodel. Our current implementation utilizes gpt3.5-turbo version of Chat-\r\nGPT [76]. We expect that the architectural basics of generative\r\nagents—memory, planning, and reflection—will likely remain the\r\nsame as language models improve. Newer language models (e.g.,\r\nGPT-4) will continue to expand the expressivity and performance\r\nof the prompts that underpin generative agents. As of writing, how-\r\never, GPT-4’s API is still invitation-only, so our agents use ChatGPT. 4.1  Memory and Retrieval\r\nChallenge:Creating generative agents that can simulate human\r\nbehavior requires reasoning about a set of experiences that is far\r\nlarger than what should be described in a prompt, as the full mem-\r\nory stream can distract the model and does not even currently fit\r\ninto the limited context window. Consider a the Isabella agent an-\r\nswering the question “What are you passionate about these days?”. First summarizing all of Isabella’s experiences to fit in the limited\r\ncontext window of the language model produces an uninformative\r\nresponse, where Isabella discusses topics such as collaborations for\r\nevents and projects and cleanliness and organization in a cafe. In-\r\nstead of summarizing, the memory stream described below surfaces\r\nrelevant memories, resulting in a more informative and specific\r\nresponse that mentions Isabella’s passion for making people feel\r\nwelcome and included, planning events and creating an atmosphere\r\nthat people can enjoy, such as the Valentine’s Day party. Approach:Thememory streammaintains a comprehensive record\r\nof the agent’s experience. It is a list of memory objects, where each\r\nobject contains a natural language description, a creation times-\r\ntamp and a most recent access timestamp. The most basic element\r\nof the memory stream is anobservation, which is an event directly\r\nperceived by an agent. Common observations include behaviors\r\nperformed by the agent themselves, or behaviors that agents per-\r\nceive being performed by other agents or non-agent objects.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"f57bc90f-c6df-483d-95ed-fa37c277573d":{"id_":"f57bc90f-c6df-483d-95ed-fa37c277573d","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"PAIRJZP0Dy5Xllq1oDxdyUjauVOFt5cKyD3HW5Xb/cM=","metadata":{},"hash":"+QBnViBi3B+/kvoIm/DeDlBR0tS4PkzHV1tI58jau5g="},"PREVIOUS":{"nodeId":"474cf858-55d5-4f43-8cec-a27d51609a03","metadata":{},"hash":"XfFOquui4F6Maul0GFUNozMjDlav3+w5mebh263Hddo="}},"hash":"+e0Jx6fgQ+BHjySCjyHllPxopwBk+CEvh9MRcwd5BjY=","text":"For\r\ninstance, Isabella Rodriguez, who works at a coffee shop, might ac-\r\ncrue the following observations over time: (1)Isabella Rodriguez is\r\nsetting out the pastries, (2)Maria Lopez is studying for a Chemistry\r\ntest while drinking coffee, (3)Isabella Rodriguez and Maria Lopez\r\nare conversing about planning a Valentine’s day party at Hobbs Cafe,\r\n(4)The refrigerator is empty.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"7af63285-ab66-4e54-83f6-b21d782e14f9":{"id_":"7af63285-ab66-4e54-83f6-b21d782e14f9","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"KXkZgpNT9PKz38Dnx81vhM48mlulLYbeCaPCPZqTPvk=","metadata":{},"hash":"+oVyMjP70JHK7VhiBV1q2NSqlerUxi/7hKc6d88e/hg="},"NEXT":{"nodeId":"59354d66-6d31-419e-a405-d603f8bab292","metadata":{},"hash":"Ip1KzW+Pj1MLletjMv1JlWcl4GDLAUd6ARr8YKwsd0E="}},"hash":"sADApz6PaYZj+ll4BhZnVyFTxo1iBTKOStK/PZ9Tk8Q=","text":"Generative AgentsarXiv, April, 2023,\r\nFigure 6: The memory stream comprises a large number of observations that are relevant and irrelevant to the agent’s current\r\nsituation. Retrieval identifies a subset of these observations that should be passed to the language model to condition its\r\nresponse to the situation. Our architecture implements a retrieval function that takes the\r\nagent’s current situation as input and returns a subset of the mem-\r\nory stream to pass on to the language model. There are many pos-\r\nsible implementations of a retrieval function, depending on what\r\nit is important that the agent consider when deciding how to act. In our context, we focus on three main components that together\r\nproduce effective results. Recencyassigns a higher score to memory objects that were re-\r\ncently accessed, so that events from a moment ago or this morning\r\nare likely to remain in the agent’s attentional sphere. In our im-\r\nplementation, we treat recency as an exponential decay function\r\nover the number of sandbox game hours since the memory was\r\nlast retrieved. Our decay factor is0.99. Importancedistinguishes mundane from core memories, by as-\r\nsigning a higher score to those memory objects that the agent\r\nbelieves to be important. For instance, a mundane event such as\r\neating breakfast in one’s room would yield a low importance score,\r\nwhereas a breakup with one’s significant other would yield a high\r\nscore. There are again many possible implementations of an im-\r\nportance score; we find that directly asking the language model to\r\noutput an integer score is effective. The full prompt appears below:\r\nOn the scale of 1 to 10, where 1 is purely mundane\r\n(e.g.,  brushing  teeth,  making  bed)  and  10  is\r\nextremely  poignant  (e.g.,  a  break  up,  college\r\nacceptance),  rate  the  likely  poignancy  of  the\r\nfollowing piece of memory. Memory: buying groceries at The Willows Market\r\nand Pharmacy\r\nRating: <fill in>\r\nThis prompt returns an integer value of2for “cleaning up the room”\r\nand8for “asking your crush out on a date. ” The importance score\r\nis generated at the time the memory object is created. Relevanceassigns a higher score to memory objects that are\r\nrelated to the current situation.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"59354d66-6d31-419e-a405-d603f8bab292":{"id_":"59354d66-6d31-419e-a405-d603f8bab292","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"KXkZgpNT9PKz38Dnx81vhM48mlulLYbeCaPCPZqTPvk=","metadata":{},"hash":"+oVyMjP70JHK7VhiBV1q2NSqlerUxi/7hKc6d88e/hg="},"PREVIOUS":{"nodeId":"7af63285-ab66-4e54-83f6-b21d782e14f9","metadata":{},"hash":"sADApz6PaYZj+ll4BhZnVyFTxo1iBTKOStK/PZ9Tk8Q="},"NEXT":{"nodeId":"d657f458-fd60-48b6-a972-f656bee47c73","metadata":{},"hash":"/d9sVaJkOXaFl1LfIFbkfXNPEPfLjGCkAp5k2iApydc="}},"hash":"Ip1KzW+Pj1MLletjMv1JlWcl4GDLAUd6ARr8YKwsd0E=","text":"Relevanceassigns a higher score to memory objects that are\r\nrelated to the current situation. What is relevant depends on the\r\nanswer to, “Relevant towhat?”, so we condition relevance on a\r\nquerymemory. If the query, for example, is that a student is dis-\r\ncussing what to study for a chemistry test with a classmate, memory\r\nobjects about their breakfast should have low relevance, whereas\r\nmemory objects about the teacher and schoolwork should have\r\nhigh relevance. In our implementation, we use the language model\r\nto generate an embedding vector of the text description of each\r\nmemory. Then, we calculate relevance as the cosine similarity be-\r\ntween the memory’s embedding vector and the query memory’s\r\nembedding vector. To calculate the final retrieval score, we normalize the recency,\r\nrelevance, and importance scores to the range of[0,1]by min-max\r\nscaling. The retrieval function scores all memories as a weighted\r\ncombination of the three elements:푠푐표푟푒=훼푟푒푐푒푛푐푦·푟푒푐푒푛푐푦+\r\n훼푖푚푝표푟푡푎푛푐푒·푖푚푝표푟푡푎푛푐푒+훼푟푒푙푒푣푎푛푐푒·푟푒푙푒푣푎푛푐푒. In our implemen-\r\ntation, all훼’s are set to 1. The top-ranked memories that fit in the\r\nlanguage model’s context window are then included in the prompt. 4.2  Reflection\r\nChallenge:Generative agents, when equipped with only raw ob-\r\nservational memory, struggle to generalize or make inferences. Consider a scenario in which Klaus Mueller is asked by the user:\r\n“If you had to choose one person of those you know to spend an\r\nhour with, who would it be?","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"d657f458-fd60-48b6-a972-f656bee47c73":{"id_":"d657f458-fd60-48b6-a972-f656bee47c73","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"KXkZgpNT9PKz38Dnx81vhM48mlulLYbeCaPCPZqTPvk=","metadata":{},"hash":"+oVyMjP70JHK7VhiBV1q2NSqlerUxi/7hKc6d88e/hg="},"PREVIOUS":{"nodeId":"59354d66-6d31-419e-a405-d603f8bab292","metadata":{},"hash":"Ip1KzW+Pj1MLletjMv1JlWcl4GDLAUd6ARr8YKwsd0E="}},"hash":"/d9sVaJkOXaFl1LfIFbkfXNPEPfLjGCkAp5k2iApydc=","text":"\" With access to only observational\r\nmemory, the agent simply chooses the person with whom Klaus","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"f543a584-310a-4924-a845-058d285c669b":{"id_":"f543a584-310a-4924-a845-058d285c669b","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"/Z59NbiciJsEPp57MibJY0UdYyVr5GBHg/IjXkRwzpU=","metadata":{},"hash":"puZ/oEeXq0c+PK/rlcTqFm6H4Rg8wxpus+5NzFmqaUs="},"NEXT":{"nodeId":"771bb3e0-36c7-4398-b610-d18e6e67db93","metadata":{},"hash":"m7Zx0CQ0W0uuwscd1m18t2k+NqBHsnFjWZ+Tn9OL9y8="}},"hash":"adbsv4MXOP9BFpT5eIKLdI4DuZ1VPomvWTU/4zpta08=","text":"arXiv, April, 2023,J.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\r\nFigure 7: A reflection tree for Klaus Mueller. The agent’s observations of the world, represented in the leaf nodes, are recur-\r\nsively synthesized to derive Klaus’s self-notion that he is highly dedicated to his research. has had the most frequent interactions: Wolfgang, his college dorm\r\nneighbor. Unfortunately, Wolfgang and Klaus only ever see each\r\nother in passing, and do not have deep interactions. A more desir-\r\nable response requires that the agent generalize from memories of\r\nKlaus spending hours on a research project to generate a higher-\r\nlevel reflection that Klaus is passionate about research, and likewise\r\nrecognize Maria putting in effort into her own research (albeit in\r\na different field), enabling a reflection that they share a common\r\ninterest. With the approach below, when Klaus is asked who to\r\nspend time with, Klaus chooses Maria instead of Wolfgang. Approach:We introduce a second type of memory, which we call\r\nareflection. Reflections are higher-level, more abstract thoughts\r\ngenerated by the agent. Because they are a type of memory, they\r\nare included alongside other observations when retrieval occurs. Reflections are generated periodically; in our implementation, we\r\ngenerate reflections when the sum of the importance scores for the\r\nlatest events perceived by the agents exceeds a certain threshold. In practice, our agents reflected roughly two or three times a day. The first step in reflection is for the agent to determine what\r\nto reflect on, by identifying questions that can be asked given the\r\nagent’s recent experiences. We query the large language model with\r\nthe 100 most recent records in the agent’s memory stream (e.g.,\r\n“Klaus Mueller is reading a book on gentrification”, “Klaus Mueller\r\nis conversing with a librarian about his research project”, “desk\r\nat the library is currently unoccupied”) and prompt the language\r\nmodel, “Given only the information above, what are 3 most salient\r\nhigh-level questions we can answer about the subjects in the state-\r\nments? ” The model’s response generates candidate questions: for\r\nexample,What topic is Klaus Mueller passionate about?andWhat\r\nis the relationship between Klaus Mueller and Maria Lopez?.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"771bb3e0-36c7-4398-b610-d18e6e67db93":{"id_":"771bb3e0-36c7-4398-b610-d18e6e67db93","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"/Z59NbiciJsEPp57MibJY0UdYyVr5GBHg/IjXkRwzpU=","metadata":{},"hash":"puZ/oEeXq0c+PK/rlcTqFm6H4Rg8wxpus+5NzFmqaUs="},"PREVIOUS":{"nodeId":"f543a584-310a-4924-a845-058d285c669b","metadata":{},"hash":"adbsv4MXOP9BFpT5eIKLdI4DuZ1VPomvWTU/4zpta08="}},"hash":"m7Zx0CQ0W0uuwscd1m18t2k+NqBHsnFjWZ+Tn9OL9y8=","text":"We use\r\nthese generated questions as queries for retrieval, and gather rele-\r\nvant memories (including other reflections) for each question. Then\r\nwe prompt the language model to extract insights and cite the par-\r\nticular records that served as evidence for the insights. The full\r\nprompt appears below:\r\nStatements about Klaus Mueller\r\n1. Klaus Mueller is writing a research paper\r\n2. Klaus Mueller enjoys reading a book\r\non gentrification\r\n3. Klaus Mueller is conversing with Ayesha Khan\r\nabout exercising [... ]\r\nWhat 5 high-level insights can you infer from\r\nthe above statements? (example format: insight\r\n(because of 1, 5, 3))\r\nThis process generates statements such asKlaus Mueller is dedicated\r\nto his research on gentrification (because of 1, 2, 8, 15). We parse and\r\nstore the statement as a reflection in the memory stream, including\r\npointers to the memory objects that were cited. Reflection explicitly allows the agents to reflect not only on\r\ntheir observations but also on other reflections: for example, the\r\nsecond statement about Klaus Mueller above is a reflection that\r\nKlaus previously had, not an observation from his environment. As a result, agents generate trees of reflections: the leaf nodes of\r\nthe tree represent the base observations, and the non-leaf nodes\r\nrepresent thoughts that become more abstract and higher-level\r\nhigher up the tree they are.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"d6f6cea9-6ee8-4cdf-b857-0cd4e4e6dcbe":{"id_":"d6f6cea9-6ee8-4cdf-b857-0cd4e4e6dcbe","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"ZCabfOkLEkcOcN0+6Phhu8wNe98Gkdg5sV6jWUbuY1s=","metadata":{},"hash":"PV9hhmumeO4MAMtNn4qSl9qKUGUFgmyLjF6sc1Gl2wA="},"NEXT":{"nodeId":"181f007b-dca1-4274-a824-e9e453e4f6c2","metadata":{},"hash":"PgX2sI1UppikluUvx3Ezw3QXwcb8HcuVZJNjuVoswS8="}},"hash":"/k/kzQeOgh79oyzB9Q91xKa+Lcp/YRA//dKfIJ6wOwc=","text":"Generative AgentsarXiv, April, 2023,\r\n4.3  Planning and Reacting\r\nChallenge:While a large language model can generate plausible be-\r\nhavior in response to situational information (e.g., [45,79]), agents\r\nneed to plan over a longer time horizon to ensure that their sequence\r\nof actions is coherent and believable. If we prompt a language model\r\nwith Klaus’s background, describe the time, and ask what action\r\nhe ought to take at the given moment, Klaus would eat lunch at 12\r\npm, but then again at 12:30 pm and 1 pm, despite having already\r\neaten his lunch twice. Optimizing for believability in the moment\r\nsacrifices believability over time. To overcome this issue, planning\r\nis essential. With the approach described below, Klaus’s afternoon\r\nplan is less gluttonous: he has lunch at Hobbs Cafe while reading\r\nat 12pm, works on his research paper at the school library at 1pm,\r\nand takes a break for a walk in the park at 3pm. Approach:Plans describe a future sequence of actions for the agent,\r\nand help keep the agent’s behavior consistent over time. A plan\r\nincludes a location, a starting time, and a duration. For instance,\r\nKlaus Mueller, who isdedicated in his researchand has an impend-\r\ning deadline4, may choose to spend his day working at his desk\r\ndrafting his research paper. An entry in a plan might state, for\r\nexample:for 180 minutes from 9am, February 12th, 2023, at Oak Hill\r\nCollege Dorm: Klaus Mueller’s room: desk, read and take notes for\r\nresearch paper. Like reflections, plans are stored in the memory\r\nstream and are included in the retrieval process. This allows the\r\nagent to consider observations, reflections, and plans all together\r\nwhen deciding how to behave. Agents may change their plans\r\nmidstream if needed. It would be unrealistic and uninteresting for an artist agent\r\nto plan on painting while sitting at a pharmacy counter for four\r\nhours without moving. A more desirable plan would involve the\r\nagent taking the necessary time to gather materials, mix paint,\r\ntake breaks, and clean up during the four-hour period in its home\r\nstudio.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"181f007b-dca1-4274-a824-e9e453e4f6c2":{"id_":"181f007b-dca1-4274-a824-e9e453e4f6c2","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"ZCabfOkLEkcOcN0+6Phhu8wNe98Gkdg5sV6jWUbuY1s=","metadata":{},"hash":"PV9hhmumeO4MAMtNn4qSl9qKUGUFgmyLjF6sc1Gl2wA="},"PREVIOUS":{"nodeId":"d6f6cea9-6ee8-4cdf-b857-0cd4e4e6dcbe","metadata":{},"hash":"/k/kzQeOgh79oyzB9Q91xKa+Lcp/YRA//dKfIJ6wOwc="},"NEXT":{"nodeId":"ea5ff498-9ac1-4fe0-af0f-754d256c9e6e","metadata":{},"hash":"YQZM7lgWI1AHN0Ug4mR4WqCNIq1dp8JLnniYuQBZ1/A="}},"hash":"PgX2sI1UppikluUvx3Ezw3QXwcb8HcuVZJNjuVoswS8=","text":"To create such plans, our approach starts top-down and\r\nthen recursively generates more detail. The first step is to create\r\na plan that outlines the day’s agenda in broad strokes. To create\r\nthe initial plan, we prompt the language model with the agent’s\r\nsummary description (e.g., name, traits, and summary of their recent\r\nexperiences) and a summary of their previous day. A full example\r\nprompt is below, which is unfinished at the bottom for the language\r\nmodel to complete:\r\nName: Eddy Lin (age: 19)\r\nInnate traits: friendly, outgoing, hospitable\r\nEddy Lin is a student at Oak Hill College studying\r\nmusic theory and composition. He loves to explore\r\ndifferent musical styles and is always looking\r\nfor ways to expand his knowledge. Eddy Lin is\r\nworking on a composition project for his college\r\nclass. He is also taking classes to learn more\r\nabout music\r\ntheory. Eddy Lin is excited about the new composition\r\nhe is working on but he wants to dedicate more\r\nhours in the day to work on it in the coming days\r\nOn  Tuesday  February  12,  Eddy  1)  woke  up  and\r\ncompleted the morning routine at 7:00 am, [. . . ]\r\n4And, in this way, bears at least a passing resemblance to the authors of this paper. 6) got ready to sleep around 10 pm. Today is Wednesday February 13. Here is Eddy’s\r\nplan today in broad strokes: 1)\r\nThis generates a rough sketch of the agent’s plan for a day, divided\r\ninto five to eight chunks: “1) wake up and complete the morning\r\nroutine at 8:00 am, 2) go to Oak Hill College to take classes starting\r\n10:00 am, [. . . ] 5) work on his new music composition from 1:00 pm\r\nto 5:00 pm, 6) have dinner at 5:30 pm, 7) finish school assignments\r\nand go to bed by 11:00 pm.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"ea5ff498-9ac1-4fe0-af0f-754d256c9e6e":{"id_":"ea5ff498-9ac1-4fe0-af0f-754d256c9e6e","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"ZCabfOkLEkcOcN0+6Phhu8wNe98Gkdg5sV6jWUbuY1s=","metadata":{},"hash":"PV9hhmumeO4MAMtNn4qSl9qKUGUFgmyLjF6sc1Gl2wA="},"PREVIOUS":{"nodeId":"181f007b-dca1-4274-a824-e9e453e4f6c2","metadata":{},"hash":"PgX2sI1UppikluUvx3Ezw3QXwcb8HcuVZJNjuVoswS8="},"NEXT":{"nodeId":"4316fd4f-e929-4f05-9259-7513c40aca0d","metadata":{},"hash":"W305xjewBu8WCHYLDVRzxhMRM3LM5DwsFAWuI5/aNoI="}},"hash":"YQZM7lgWI1AHN0Ug4mR4WqCNIq1dp8JLnniYuQBZ1/A=","text":"”\r\nThe agent saves this plan in the memory stream and then re-\r\ncursively decomposes it to create finer-grained actions, first into\r\nhour-long chunks of actions—Eddy’s plan towork on his new mu-\r\nsic composition from 1:00 pm to 5:00 pmbecomes1:00 pm: start\r\nby brainstorming some ideas for his music composition [... ] 4:00 pm:\r\ntake a quick break and recharge his creative energy before reviewing\r\nand polishing his composition. We then recursively decompose this\r\nagain into 5–15 minute chunks: e.g.,4:00 pm: grab a light snack,\r\nsuch as a piece of fruit, a granola bar, or some nuts. 4:05 pm: take a\r\nshort walk around his workspace [... ] 4:50 pm: take a few minutes to\r\nclean up his workspace. This process can be adjusted to match the\r\ndesired granularity. 4.3.1    Reacting and Updating Plans.Generative agents operate in\r\nan action loop where, at each time step, they perceive the world\r\naround them and those perceived observations are stored in their\r\nmemory stream. We prompt the language model with these obser-\r\nvations to decide whether the agent should continue with their\r\nexisting plan, or react. Standing at an easel and painting, for exam-\r\nple, might trigger an observation of the easel, but this is unlikely to\r\nprompt a reaction. However, if Eddy’s father John records that he\r\nsees Eddy taking a short walk in the house garden, the outcome is\r\ndifferent. The prompt is below, with[Agent’s Summary Descrip-\r\ntion]standing in for a dynamically-generated, paragraph-long\r\nsummary of the agent’s overall goals and disposition, which is\r\ndescribed in Appendix A:\r\n[Agent’s Summary Description]\r\nIt is February 13, 2023, 4:56 pm. John Lin’s status: John is back home early from\r\nwork. Observation: John saw Eddy taking a short walk\r\naround his workplace. Summary of relevant context from John’s memory:\r\nEddy Lin is John’s Lin’s son. Eddy Lin has been\r\nworking on a music composition for his class. Eddy\r\nLin likes to walk around the garden when he is\r\nthinking about or listening to music.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"4316fd4f-e929-4f05-9259-7513c40aca0d":{"id_":"4316fd4f-e929-4f05-9259-7513c40aca0d","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"ZCabfOkLEkcOcN0+6Phhu8wNe98Gkdg5sV6jWUbuY1s=","metadata":{},"hash":"PV9hhmumeO4MAMtNn4qSl9qKUGUFgmyLjF6sc1Gl2wA="},"PREVIOUS":{"nodeId":"ea5ff498-9ac1-4fe0-af0f-754d256c9e6e","metadata":{},"hash":"YQZM7lgWI1AHN0Ug4mR4WqCNIq1dp8JLnniYuQBZ1/A="}},"hash":"W305xjewBu8WCHYLDVRzxhMRM3LM5DwsFAWuI5/aNoI=","text":"Should John react to the observation, and if so,\r\nwhat would be an appropriate reaction? The context summary is generated through two prompts that re-\r\ntrieve memories via the queries “What is [observer]’s relationship\r\nwith the [observed entity]? ” and “[Observed entity] is [action status\r\nof the observed entity]”, and their answers summarized together. The output suggests thatJohn could consider asking Eddy about his\r\nmusic composition project. We then regenerate the agent’s existing\r\nplan starting from the time when the reaction takes place. Finally,","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"3d990f3f-b05e-4b3b-bcc2-add07024bf1b":{"id_":"3d990f3f-b05e-4b3b-bcc2-add07024bf1b","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"cTOGTUXNQcx3nKlLuT9dWjR6Ub7qXncGLL02VsfmKMo=","metadata":{},"hash":"QUnAvvOKKFcyXoZK7iEj6Ep8HDj+V1zVZ0ceqS3C4Zg="},"NEXT":{"nodeId":"9f5b4321-366a-43c7-93c6-0aa230ea2b8f","metadata":{},"hash":"CjHaC3W+J5aEBAdCUt2bgW6jpkzjThMBZACcJq8u/M8="}},"hash":"fGMzb06e17AyLSVnPtV0sQPe+4ZcKsUcgalDQngZp0o=","text":"arXiv, April, 2023,J.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\r\nif the action indicates an interaction between agents, we generate\r\ntheir dialogue. 4.3.2    Dialogue.Agents converse as they interact with each other. We generate agents’ dialogue by conditioning their utterances on\r\ntheir memories about each other. For example, when John initiates\r\nhis conversation with Eddy, we generate John’s first utterance\r\nby using his summarized memory about Eddy and the intended\r\nreaction when he decided to ask Eddy about his composition project:\r\n[Agent’s Summary Description]\r\nIt is February 13, 2023, 4:56 pm. John Lin’s status: John is back home early from\r\nwork. Observation: John saw Eddy taking a short walk\r\naround his workplace. Summary of relevant context from John’s memory:\r\nEddy Lin is John’s Lin’s son. Eddy Lin has been\r\nworking on a music composition for his class. Eddy\r\nLin likes to walk around the garden when he is\r\nthinking about or listening to music. John is asking Eddy about his music composition\r\nproject. What would he say to Eddy? The result:“Hey Eddy, how’s the music composition project for your\r\nclass coming along?”From Eddy’s perspective, John initiating the\r\ndialogue is seen as an event to which he may want to react. So, just\r\nas John did, Eddy retrieves and summarizes his memory about his\r\nrelationship with John, as well as his memory that may be related\r\nto John’s last utterance in the dialogue. If he decides to respond,\r\nwe generate Eddy’s utterance using his summarized memory and\r\nthe current dialogue history:\r\n[Agent’s Summary Description]\r\nIt is February 13, 2023, 4:56 pm. Eddy Lin’s status: Eddy is taking a short walk\r\naround his workplace. Observation: John is initiating a conversation\r\nwith Eddy. Summary of relevant context from Eddy’s memory:\r\nJonn Lin is Eddy Lin’s father. John Lin is caring\r\nand is interested to learn more about Eddy Lin’s\r\nschool  work.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"9f5b4321-366a-43c7-93c6-0aa230ea2b8f":{"id_":"9f5b4321-366a-43c7-93c6-0aa230ea2b8f","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"cTOGTUXNQcx3nKlLuT9dWjR6Ub7qXncGLL02VsfmKMo=","metadata":{},"hash":"QUnAvvOKKFcyXoZK7iEj6Ep8HDj+V1zVZ0ceqS3C4Zg="},"PREVIOUS":{"nodeId":"3d990f3f-b05e-4b3b-bcc2-add07024bf1b","metadata":{},"hash":"fGMzb06e17AyLSVnPtV0sQPe+4ZcKsUcgalDQngZp0o="},"NEXT":{"nodeId":"f205437b-7f28-4ed5-b775-46e72847af2c","metadata":{},"hash":"3/EwBS1hx+01FjJrGGRuSTr89n+hNipnGTVZ7GO0E40="}},"hash":"CjHaC3W+J5aEBAdCUt2bgW6jpkzjThMBZACcJq8u/M8=","text":"John  Lin  knows  that  Eddy  Lin  is\r\nworking on a music composition. Here is the dialogue history:\r\nJohn: Hey Eddy, how’s the music composition project\r\nfor your class coming along? How would Eddy respond to John? This generates Eddy’s response:“Hey Dad, it’s going well. I’ve been\r\ntaking walks around the garden to clear my head and get some in-\r\nspiration.”The continuation of this dialogue is generated using the\r\nsame mechanism until one of the two agents decides to end the\r\ndialogue. 5  SANDBOX ENVIRONMENT\r\nIMPLEMENTATION\r\nThe Smallville sandbox game environment is built using the Phaser\r\nweb game development framework [56]. The visual environment\r\nsprites, including agent avatars, as well as an environment map\r\nand collision map that we authored, are imported into Phaser. We supplement the sandbox development framework with a\r\nserver that makes the sandbox information available to generative\r\nagents and enables generative agents to move and influence the\r\nsandbox environment. The server maintains a JSON data structure\r\nthat contains information about each agent in the sandbox world,\r\nincluding their current location, a description of their current action,\r\nand the sandbox object they are interacting with. At each sandbox\r\ntime step, the sandbox server parses the JSON for any changes\r\ncoming from the generative agents, moves the agents to their new\r\npositions, and updates the status of any sandbox objects that the\r\nagents are interacting with (e.g., changing the status of the coffee\r\nmachine from “idle” to “brewing coffee” if an agent’s action is\r\n“making espresso for a customer @ Hobbs Cafe: counter: coffee\r\nmachine”). The sandbox server is also responsible for sending all\r\nagents and objects that are within a preset visual range for each\r\nagent to that agent’s memory, so the agent can react appropriately. The agent’s output action then updates the JSON, and the process\r\nloops for the next time step. End users initialize a new agent with a brief natural language\r\ndescription, as in the paragraph about Jon Lin in Section 3.1. In our\r\nimplementation, we split this semicolon-delimited list of character-\r\nistics up into a set of memories. These serve as the initial memories\r\nthat determine the agent’s behavior.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"f205437b-7f28-4ed5-b775-46e72847af2c":{"id_":"f205437b-7f28-4ed5-b775-46e72847af2c","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"cTOGTUXNQcx3nKlLuT9dWjR6Ub7qXncGLL02VsfmKMo=","metadata":{},"hash":"QUnAvvOKKFcyXoZK7iEj6Ep8HDj+V1zVZ0ceqS3C4Zg="},"PREVIOUS":{"nodeId":"9f5b4321-366a-43c7-93c6-0aa230ea2b8f","metadata":{},"hash":"CjHaC3W+J5aEBAdCUt2bgW6jpkzjThMBZACcJq8u/M8="}},"hash":"3/EwBS1hx+01FjJrGGRuSTr89n+hNipnGTVZ7GO0E40=","text":"These serve as the initial memories\r\nthat determine the agent’s behavior. These memories are initial\r\nstarting points: as the agents gain more experience in the sandbox\r\nworld, and as more records saturate the memory stream, the agent’s\r\nsummary and behavior will evolve. 5.1  From Structured World Environments to\r\nNatural Language, And Back Again\r\nThe architecture of generative agents operates using natural lan-\r\nguage. Therefore, we need a mechanism to ground the agent’s\r\nreasoning to the sandbox world. To achieve this, we represent the\r\nsandbox environment—areas and objects—as a tree data structure,\r\nwith an edge in the tree indicating a containment relationship in\r\nthe sandbox world. We convert this tree into natural language to\r\npass to the generative agents. For instance, “stove” being a child of\r\n“kitchen” is rendered into “there is a stove in the kitchen. ”\r\nAgents build individual tree representations of the environment\r\nas they navigate it — subgraphs of the overall sandbox environment\r\ntree. We initialize each agent with an environment tree capturing\r\nthe spaces and objects that the agent should be aware of: the rooms\r\nand objects in their living quarters, their workplace, and commonly\r\nvisited stores and shops. As the agents navigate the sandbox world,\r\nthey update this tree to reflect newly perceived areas. Agents are\r\nnot omniscient: their tree may get out of date as they leave an area,\r\nand is updated when they re-enter the area. To determine the appropriate location for each action, we tra-\r\nverse the agent’s stored environment tree and flatten a portion of\r\nit into natural language to prompt the language model. Recursively\r\nstarting at the root of the agent’s environment tree, we prompt the\r\nmodel to find the most suitable area. For example, if Eddy’s agent\r\nindicated that he shouldtake a short walk around his workspace:\r\n[Agent’s Summary Description]\r\nEddy Lin is currently in The Lin family’s house:","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"8c296ed5-9b84-48b0-ab83-536eab935b2e":{"id_":"8c296ed5-9b84-48b0-ab83-536eab935b2e","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"QOBuaRMBoUNgpwf+vysZholtitQR86KxfrvvfQzixrQ=","metadata":{},"hash":"UfZtcCelCnaQ+QHCtbmCIkS12w/hyYmBkCIUGu2Q9So="},"NEXT":{"nodeId":"341366c4-5e23-48ad-a4b5-b3230ab3bf1e","metadata":{},"hash":"Feq4CbmrqVd5d0bqXGdkGf43gKbop27zXkRtYoVVjh4="}},"hash":"cclqwf6nnEsmopJxQeXiu/yqbduBSdh/FBMr9mf8MtQ=","text":"Generative AgentsarXiv, April, 2023,\r\nEddy Lin’s bedroom: desk) that has Mei and John\r\nLin’s\r\nbedroom, Eddy Lin’s bedroom, common room, kitchen,\r\nbathroom, and garden. Eddy Lin knows of the following areas: The Lin\r\nfamily’s house, Johnson Park, Harvey Oak Supply\r\nStore,  The  Willows  Market  and  Pharmacy,  Hobbs\r\nCafe, The Rose and Crown Pub. *  Prefer  to  stay  in  the  current  area  if  the\r\nactivity can be done there. Eddy Lin is planning to take a short walk around\r\nhis workspace. Which area should Eddy Lin go to? This outputsThe Lin family’s house. We then use the same process\r\nrecursively to determine the most appropriate subarea within the\r\nchosen area until we reach a leaf node of the agent’s environment\r\ntree. In the example above, the result of this traversal isThe Lin\r\nfamily’s house: garden: house garden. Finally, we use traditional\r\ngame path algorithms to animate the agent’s movement so that it\r\ntravels to the location indicated by the leaf node. When an agent executes an action on an object, we prompt the\r\nlanguage model to ask what happens to the state of the object. For\r\nexample, if Isabella’s generative agent outputs the action “making\r\nespresso for a customer”, a query to the language model indicates in\r\nresponse that the state of the coffee machine in Hobbs Cafe should\r\nchange from “off” to “brewing coffee”. 6  CONTROLLED EVALUATION\r\nGenerative agents, as individual agents and as groups, aim to pro-\r\nduce believable behavior based on their environment and experi-\r\nences. In our evaluation, we investigate the capacity and limitations\r\nof generative agents. Do individual agents properly retrieve past\r\nexperience, and generate believable plans, reactions, and thoughts\r\nthat make up their behavior? Does a community of agents illustrate\r\ninformation diffusion, relationship formation, and agent coordina-\r\ntion across different pockets of the community? We evaluate generative agents in two stages. We begin with a\r\nmore tightly controlled evaluation in this section, where we individ-\r\nually assess agent responses to understand whether they generate\r\nbelievable behavior in narrowly defined contexts.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"341366c4-5e23-48ad-a4b5-b3230ab3bf1e":{"id_":"341366c4-5e23-48ad-a4b5-b3230ab3bf1e","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"QOBuaRMBoUNgpwf+vysZholtitQR86KxfrvvfQzixrQ=","metadata":{},"hash":"UfZtcCelCnaQ+QHCtbmCIkS12w/hyYmBkCIUGu2Q9So="},"PREVIOUS":{"nodeId":"8c296ed5-9b84-48b0-ab83-536eab935b2e","metadata":{},"hash":"cclqwf6nnEsmopJxQeXiu/yqbduBSdh/FBMr9mf8MtQ="},"NEXT":{"nodeId":"f6a84758-49c5-439f-b0e0-6807f9c10b09","metadata":{},"hash":"71j92fe1Jwoan8O4lxrJtO/BYd9L5pZCVEOuIYPhuJc="}},"hash":"Feq4CbmrqVd5d0bqXGdkGf43gKbop27zXkRtYoVVjh4=","text":"Then, in our end-\r\nto-end analysis of the agent community over two full days, we\r\ninvestigate their emergent behavior as a collective as well as errors\r\nand boundary conditions. 6.1  Evaluation Procedure\r\nTo assess generative agents in Smallville, we take advantage of\r\nthe fact that generative agents will respond to natural language\r\nquestions. So, we “interview” agents to probe their ability to re-\r\nmember past experiences, plan future actions based on their expe-\r\nriences, react appropriately to unexpected events, and reflect on\r\ntheir performance to improve their future actions. To respond to\r\nthese questions properly, the agents must successfully retrieve and\r\nsynthesize information. Our dependent variable is thebelievabil-\r\nityof the behavior, a central dependent variable in prior work on\r\nagents (e.g., [9]). The interview include five question categories, each designed\r\nto assess one of the five key areas: maintaining self-knowledge,\r\nretrieving memory, generating plans, reacting, and reflecting. For\r\neach, we ask five questions that challenge the agents to demonstrate\r\ntheir abilities in that area:\r\n•Self-knowledge: We ask questions such as “Give an introduc-\r\ntion of yourself” or “Describe your typical weekday schedule\r\nin broad strokes” that require the agent to maintain an un-\r\nderstanding of their core characteristics. •Memory: We ask questions that prompt the agent to retrieve\r\nparticular events or dialogues from their memory to answer\r\nproperly, such as “Who is [name]? ” or “Who is running for\r\nmayor? ”\r\n•Plans: We ask questions that require the agent to retrieve\r\ntheir long-term plans, such as “What will you be doing at 10\r\nam tomorrow? ”\r\n•Reactions: As a baseline of believable behavior, we present\r\nhypothetical situations for which the agent needs to respond\r\nbelievably: “Your breakfast is burning! What would you do? ”\r\n•Reflections: We ask questions that require the agents to lever-\r\nage their deeper understanding of others and themselves\r\ngained through higher-level inferences, such as “If you were\r\nto spend time with one person you met recently, who would\r\nit be and why? ”\r\nThe full list of questions and a sample of agent responses are in-\r\ncluded in Appendix B.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"f6a84758-49c5-439f-b0e0-6807f9c10b09":{"id_":"f6a84758-49c5-439f-b0e0-6807f9c10b09","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"QOBuaRMBoUNgpwf+vysZholtitQR86KxfrvvfQzixrQ=","metadata":{},"hash":"UfZtcCelCnaQ+QHCtbmCIkS12w/hyYmBkCIUGu2Q9So="},"PREVIOUS":{"nodeId":"341366c4-5e23-48ad-a4b5-b3230ab3bf1e","metadata":{},"hash":"Feq4CbmrqVd5d0bqXGdkGf43gKbop27zXkRtYoVVjh4="}},"hash":"71j92fe1Jwoan8O4lxrJtO/BYd9L5pZCVEOuIYPhuJc=","text":"Agents were sampled from the end of a two game-day simulation\r\nwith the full architecture, by which time they had accrued a number\r\nof interactions and memories that should shape their responses. To gather feedback on believability of the responses, we recruited\r\nparticipants as human evaluators and tasked them with watching a\r\nreplay of a randomly chosen agent’s life in Smallville. Participants\r\nhad access to all information stored in the agent’s memory stream. The study was a within-subjects design, where 100 participants\r\ncompared interview responses generated by four different agent\r\narchitectures and a human author condition for the same agent. The\r\nexperiment displayed one randomly chosen question from each of\r\nthe five question categories, along with the agent’s responses gen-\r\nerated from each condition. The evaluators ranked the believability\r\nof all of the conditions from most to least believable. 6.2  Conditions\r\nAll conditions were used to independently answer each of the inter-\r\nview questions. We compared the generative agent architecture to\r\nablations that disabled the agents’ access to some of all of its three\r\ntypes of memory in its memory stream—observation, reflection, and\r\nplanning—and to a human-generated condition. There are three\r\nablated architectures: ano observation, no reflection, no planning\r\narchitecture without access to anything in the memory stream such\r\nas observations, plans, and reflections; ano reflection, no planning\r\nwith access to observations in the memory stream but no access\r\nto plans or reflections; and ano reflections architecturewith access\r\nto observations and plans but without access to reflections. Theno\r\nobservation, no reflection, no planningcondition effectively repre-\r\nsents the previous state of the art for agents created through large\r\nlanguage models [11,45,79]. Architectures were given equivalent\r\naccess to all memories accrued by the agent up until the moment","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"549a4628-66c2-4205-bc9a-5de1a0961b97":{"id_":"549a4628-66c2-4205-bc9a-5de1a0961b97","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Hrmmwe3rOAnxXCuPYAq2zzif6jckmhc0RL/0Wmd91iA=","metadata":{},"hash":"rCyVBEAt4atv73DuOY47PlhO06De1iV7YB727F2C2DU="},"NEXT":{"nodeId":"683d4f4c-a48f-4dff-a04e-18498d6661e3","metadata":{},"hash":"n/Ra2gcTtl6VTTFfn2oXFw0ORShh+DSDtCa00lHm9E0="}},"hash":"L9j01bMHfZtJ/9Bmk+9S3gDqnKdOa6SjDxoIQ1+q/OU=","text":"arXiv, April, 2023,J.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\r\nof the interview, so the differences observed here are likely to rep-\r\nresent a conservative estimate of the true differences: in reality, the\r\nablated architectures would not have followed the same path as\r\nthe full architecture through the two day simulation. We chose to\r\ndesign the experiment this way as re-simulating for each architec-\r\nture would cause the simulations to diverge into different states,\r\nmaking comparison challenging. In addition to the ablation conditions, we added a human crowd-\r\nworker roleplay condition that is intended to provide a human\r\nbaseline. We do not intend this baseline to capture maximal hu-\r\nman expert performance: instead, we aim to use this condition\r\nto identify whether the architecture passes a basic level of behav-\r\nioral competency, so that we are not just comparing ablations to\r\neach other with no behavioral grounding. We recruited a unique\r\nworker for each of the 25 agents and tasked them with watching\r\na replay of that agent’s sandbox life and inspecting its memory\r\nstream. We then asked the worker to roleplay and author responses\r\nto the interview questions in the voice of the agent whose replay\r\nthey watched. To ensure that the human-authored responses met\r\nat least a baseline expectation in quality, the first author manually\r\ninspected the workers’ responses to the question “Describe your\r\ntypical weekday schedule in broad strokes” to confirm that the\r\nresponses were written in coherent sentences and in the voice of\r\nthe agent. Four sets of human-generated responses did not meet\r\nthese criteria and were re-generated by other workers. 6.3  Human Evaluators\r\nWe required that our evaluators be in the U.S., fluent in English,\r\nand older than 18 years old. They were paid at the rate of $15.00\r\nper hour [86], and provided consent by agreeing to a consent form\r\nthat was approved by our institution’s IRB. We recruited 100 evalu-\r\nators from Prolific, an online platform for recruiting study partic-\r\nipants [82], whose participation lasted around 30 minutes.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"683d4f4c-a48f-4dff-a04e-18498d6661e3":{"id_":"683d4f4c-a48f-4dff-a04e-18498d6661e3","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Hrmmwe3rOAnxXCuPYAq2zzif6jckmhc0RL/0Wmd91iA=","metadata":{},"hash":"rCyVBEAt4atv73DuOY47PlhO06De1iV7YB727F2C2DU="},"PREVIOUS":{"nodeId":"549a4628-66c2-4205-bc9a-5de1a0961b97","metadata":{},"hash":"L9j01bMHfZtJ/9Bmk+9S3gDqnKdOa6SjDxoIQ1+q/OU="},"NEXT":{"nodeId":"a023fe9b-45d7-4378-bacf-78e2ae80f354","metadata":{},"hash":"CDughtn8hhIpg2R5AqEQhizn4AgJbRoykKAgUerJXyI="}},"hash":"n/Ra2gcTtl6VTTFfn2oXFw0ORShh+DSDtCa00lHm9E0=","text":"Their\r\nmean age score of our participants was 4.86 (SD=1.11; 3=“18-24\r\nyears old,” 4=“25-34 years old”), and 25 of them identified themselves\r\nas female, 73 as male, and 2 as non-binary. 42 of the participants\r\nheld a bachelor’s degree, 5 a higher degree, 13 an associate’s de-\r\ngree, and the rest a high school diploma or some high school-level\r\neducation. 73.0% of our participants identified as Caucasian, 7.0%\r\nas Hispanic, 6.0% as Asian, 10.0% as African American, and 4.0% as\r\nother. 6.4  Analysis\r\nOur experiment produced 100 sets of rank data, where each partici-\r\npant ranked the five conditions by believability. To translate this\r\nrank data into interval data for interpretable comparison, we used\r\nthe ranks to calculate a TrueSkill rating [41] for each condition. TrueSkill is a generalization of the Elo chess rating system [28] for\r\na multi-player environment, and has been used by XBox Live for\r\nplayer ranking from competitive game performance. Given a set of\r\nranked outcomes, TrueSkill outputs a mean rating value휇and vari-\r\nance휎for each condition. Conditions with the same rating should\r\nroughly be a toss-up, with each winning half of the comparisons\r\nbetween the two conditions; higher scores indicate conditions that\r\nbeat lower-ranked conditions in the rankings. Figure 8: The full generative agent architecture of gener-\r\native agents produces more believable behavior than ab-\r\nlatedarchitecturesandthehumancrowdworkers.Eachaddi-\r\ntional ablation reduces the performance of the architecture. Separately, to investigate statistical significance of this result, we\r\napplied the Kruskal-Wallis test [55], a non-parametric alternative\r\nto the one-way ANOVA, to the raw ranks data. We then performed\r\nthe Dunn post-hoc test [97] to identify any pairwise differences\r\nbetween the conditions. Finally, we adjusted the p-values for mul-\r\ntiple comparisons in the Dunn test using the Holm-Bonferroni\r\nmethod [44].","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"a023fe9b-45d7-4378-bacf-78e2ae80f354":{"id_":"a023fe9b-45d7-4378-bacf-78e2ae80f354","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Hrmmwe3rOAnxXCuPYAq2zzif6jckmhc0RL/0Wmd91iA=","metadata":{},"hash":"rCyVBEAt4atv73DuOY47PlhO06De1iV7YB727F2C2DU="},"PREVIOUS":{"nodeId":"683d4f4c-a48f-4dff-a04e-18498d6661e3","metadata":{},"hash":"n/Ra2gcTtl6VTTFfn2oXFw0ORShh+DSDtCa00lHm9E0="}},"hash":"CDughtn8hhIpg2R5AqEQhizn4AgJbRoykKAgUerJXyI=","text":"Furthermore,  the  first  author  conducted  an  inductive  analy-\r\nsis [94] to study the qualitative distinctions between the responses\r\nproduced in each condition. We employed qualitative open cod-\r\ning [32] in two phases. In the first phase, we generated codes that\r\nclosely represented the generated responses at the sentence level. In the second phase, we synthesized the resulting codes from the\r\nfirst phase to extract higher-level themes. We utilized these themes\r\nto compare the types of responses generated in our study. 6.5  Results\r\nOur findings suggest that the full architecture of generative agents\r\ngenerates the most believable behavior among all study conditions. We contrast the full architecture’s responses to those of other con-\r\nditions below. However, we also report that the full architecture\r\nwas not without flaws and illustrate its modes of failures. 6.5.1    The full architecture bests other conditions.As seen in Fig-\r\nure 8, the full generative agent architecture produced the most\r\nbelievable behavior (휇=29.89;휎=0.72). Performance degraded\r\nwith the removal of each component in the ablation conditions:\r\nthe ablated architecture with no access to reflection was the next\r\nbest (휇=26.88;휎=0.69), followed by no access to reflection or\r\nplanning (휇=25.64;휎=0.68), followed by the human condition\r\n(휇=22.95;휎=0.69). The ablated architecture with no access to\r\nmemory, planning, or reflection performed the worst of all con-\r\nditions (휇=21.21;휎=0.70). TrueSkill models each condition’s\r\nskill value asN(휇, 휎2), allowing us to get a sense of effect size\r\nthrough Cohen’s d. Comparing the condition representing prior\r\nwork (with no memory, planning, or reflection [11,45,79]) to the","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"1466be7a-22dc-4ede-9eef-ddcc132da3d8":{"id_":"1466be7a-22dc-4ede-9eef-ddcc132da3d8","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"rq1j9WKJUAxqvzFjw0t34+yxf/EtAdhFcL10nnHZTv8=","metadata":{},"hash":"U9nLG2KrNksIFe2Y80JR0LYak+Ii8GjEIMoHrK9SeYU="},"NEXT":{"nodeId":"896cd077-9197-4c39-aa20-d457f81f4ab4","metadata":{},"hash":"uKFU8RmujtUk+FlFMGtzN9xCrcOeTH59xRPfuF1xYwA="}},"hash":"wQIRfh0GWTca3Ho5lgvdagjMWFTbZYuEng3mb4ADzOI=","text":"Generative AgentsarXiv, April, 2023,\r\nfull architecture produces a standardized effect size of푑=8.16, or\r\neight standard deviations. A Kruskal-Wallis test confirms the overall statistical significance\r\nof the differences in ranks between the conditions (퐻(4)=150.29,\r\n푝<0.001). Dunn post-hoc tests confirm that all pairwise differences\r\nbetween conditions were significant (푝<0.001), with the exception\r\nof the human condition and the fully ablated baseline—the two\r\nworst-performing conditions. 6.5.2    Generative agents remember, but with embellishments.Gener-\r\native agents equipped with a complete memory module are capable\r\nof recalling past experiences and answering questions in a manner\r\nthat is consistent with their self-knowledge across a wide range\r\nof contexts. For instance, Abigail Chen, an animator, responded\r\nto the question, “Give an introduction of yourself”, in a consistent\r\nand believable manner, stating her age, interests, and passion for\r\ncreative projects:Hi, I’m Abigail. I’m 25 years old and passionate\r\nabout creative projects. I like to work on art and animation projects,\r\nand I’m always looking for new ways to combine art and technology. Without access to her observational memory, Abigail denied aware-\r\nness of Rajiv Patel, an acquaintance in the sandbox world. However,\r\nwith the aid of memory, she was able to successfully recall Ra-\r\njiv and describe him:Rajiv Patel is an incredible person. He is very\r\nenthusiastic about projects that involve poetry, artwork. Generative agents’ memory was not without flaws: they can fail\r\nto retrieve the correct instances from their memory. For instance,\r\nwhen asked about the local election, Rajiv Patel responded withI\r\nhaven’t been following the election too closely, even though he had\r\nheard about Sam’s candidacy. In some cases, the agents would re-\r\ntrieve an incomplete memory fragment: when Tom was asked about\r\nIsabella’s Valentine’s Day party, he respondedUh, I’m actually not\r\nsure if there is a Valentine’s Day party.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"896cd077-9197-4c39-aa20-d457f81f4ab4":{"id_":"896cd077-9197-4c39-aa20-d457f81f4ab4","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"rq1j9WKJUAxqvzFjw0t34+yxf/EtAdhFcL10nnHZTv8=","metadata":{},"hash":"U9nLG2KrNksIFe2Y80JR0LYak+Ii8GjEIMoHrK9SeYU="},"PREVIOUS":{"nodeId":"1466be7a-22dc-4ede-9eef-ddcc132da3d8","metadata":{},"hash":"wQIRfh0GWTca3Ho5lgvdagjMWFTbZYuEng3mb4ADzOI="},"NEXT":{"nodeId":"55658231-d7b3-4f6c-9cc5-fda92b4f6686","metadata":{},"hash":"7eQEUUK38c7o/GCVib/wsNTlTG6DXLnzKfEuBexL2Wo="}},"hash":"uKFU8RmujtUk+FlFMGtzN9xCrcOeTH59xRPfuF1xYwA=","text":"But I do remember that I need\r\nto discuss the upcoming local mayoral election and my thoughts on\r\nSam Moore with Isabella Rodriguez at the party, if one is happen-\r\ning!In this case, Tom retrieved the memory where he and Isabella\r\nplanned to discuss the election at the party, but not the memory\r\nwhere he heard about the party in the first place, leading Tom to\r\nbe certain of what he’s supposed to do at the party but uncertain\r\nof whether the party actually exists in the first place. At times, the agents hallucinated embellishments to their knowl-\r\nedge. It was rare for the agents to completely fabricate their knowl-\r\nedge: they may fail to recall certain events having taken place and\r\nrespond by saying so, but they did not answer affirmatively about\r\nan experience that they did not have. However, they still may hal-\r\nlucinate to embellish their knowledge. For example, Isabella was\r\naware of Sam’s candidacy in the local election, and she confirmed\r\nthis when asked. However, she also added thathe’s going to make\r\nan announcement tomorroweven though Sam and Isabella had dis-\r\ncussed no such plans. Agents may also embellish their knowledge\r\nbased on the world knowledge encoded in the language model\r\nused to generate their responses, as seen when Yuriko described\r\nher neighbor, Adam Smith, as a neighbor economist whoauthored\r\nWealth of Nations,a book authored by an 18th-century economist\r\nof the same name. 6.5.3    Reflection is required for synthesis.Reflection was an advan-\r\ntage for generative agents when making decisions that required\r\na deeper synthesis of their experiences. For instance, when asked\r\nwhat she might get Wolfgang Schulz for his birthday, Maria Lopez\r\nwith no access to reflection responded by acknowledging her uncer-\r\ntainty, stating that she did not know what Wolfgang likes, despite\r\nhaving had many interactions with him. However, with access to\r\nreflection memories, Maria answered confidently,“Since he’s inter-\r\nested in mathematical music composition, I could get him something\r\nrelated to that. Maybe some books about music composition or some-\r\nthing related, or maybe some special software he could use for that.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"55658231-d7b3-4f6c-9cc5-fda92b4f6686":{"id_":"55658231-d7b3-4f6c-9cc5-fda92b4f6686","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"rq1j9WKJUAxqvzFjw0t34+yxf/EtAdhFcL10nnHZTv8=","metadata":{},"hash":"U9nLG2KrNksIFe2Y80JR0LYak+Ii8GjEIMoHrK9SeYU="},"PREVIOUS":{"nodeId":"896cd077-9197-4c39-aa20-d457f81f4ab4","metadata":{},"hash":"uKFU8RmujtUk+FlFMGtzN9xCrcOeTH59xRPfuF1xYwA="},"NEXT":{"nodeId":"987f1095-3fdf-4f8d-8f3c-b470839ec2a6","metadata":{},"hash":"PhwZu2hkynwW+MD8JhLwKzFU8uboFSNMdwJ/4aa0sms="}},"hash":"7eQEUUK38c7o/GCVib/wsNTlTG6DXLnzKfEuBexL2Wo=","text":"”\r\n7  END-TO-END EVALUATION\r\nWhat types of emergent community behavior do we observe among\r\ngenerative agents, and where does their believability fall short in\r\nan extended simulation? In this section, we describe the results\r\nfrom a deployment in which we allowed 25 agents to interact with\r\neach other continuously over two full game days in Smallville. 7.1  Emergent Social Behaviors\r\nTo examine emergent behaviors in the agent community, we de-\r\nsigned descriptive measurements for the 25 agents in Smallville that\r\nprobe three forms of emergent outcomes: information diffusion,\r\nrelationship formation, and agent coordination. 7.1.1    Measurements.Information diffusion is a common and well-\r\nstudied phenomenon in the social and behavioral sciences (e.g., [27]). We should expect that if there is important information, the agents\r\nshould spread it amongst themselves. To test whether this happens,\r\nwe measure the spread of two particular pieces of information over\r\ntwo days in the game world: Sam’s candidacy for village mayor\r\nand Isabella’s Valentine’s Day party at Hobbs Cafe. At the start of\r\nthe simulation, both pieces of information were held only by their\r\nrespective originators, Sam for the candidacy and Isabella for the\r\nparty. To observe whether the information has spread, we engage\r\nin an interview at the end of the two game days with each of the 25\r\nagents and ask: \"Did you know there is a Valentine’s Day party? \"\r\nand \"Do you know who is running for mayor? \"\r\nWe conducted an analysis of the agents’ responses by labeling\r\nthem with a “yes” if they indicated knowledge of the information\r\nand “no” if they did not. For instance, Tamara Taylor responded\r\nto the question about the party with“No, I did not know there was\r\na Valentine’s day party”and to the question about Sam’s candidacy\r\nwith“I’m not sure who is running for the election,”so we assigned\r\n“no” for both of her responses. In contrast, Klaus Mueller responded\r\nto the party question with“Yes, Isabella Rodriguez invited me to a\r\nValentine’s Day party at Hobbs Cafe on February 14th”and to the\r\nquestion about Sam’s candidacy with“I know that Sam Moore has\r\nexpressed interest in running for local mayor,”so we assigned “yes”\r\nfor both his responses.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"987f1095-3fdf-4f8d-8f3c-b470839ec2a6":{"id_":"987f1095-3fdf-4f8d-8f3c-b470839ec2a6","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"rq1j9WKJUAxqvzFjw0t34+yxf/EtAdhFcL10nnHZTv8=","metadata":{},"hash":"U9nLG2KrNksIFe2Y80JR0LYak+Ii8GjEIMoHrK9SeYU="},"PREVIOUS":{"nodeId":"55658231-d7b3-4f6c-9cc5-fda92b4f6686","metadata":{},"hash":"7eQEUUK38c7o/GCVib/wsNTlTG6DXLnzKfEuBexL2Wo="}},"hash":"PhwZu2hkynwW+MD8JhLwKzFU8uboFSNMdwJ/4aa0sms=","text":"Additionally, for every response that con-\r\nfirmed the agents’ knowledge of the information, we verified that\r\nthe agents did not hallucinate their responses by locating the spe-\r\ncific dialogue in their memory stream that provided them with\r\nthe information. We report the percentage of agents holding the\r\ninformation at the end of the simulation. We should also expect that agents form ties with each other over\r\nthe course of the simulation. To verify relationship formation, we\r\nuse a similar interview process where we ask each agent about\r\ntheir knowledge of every other agent by asking, \"Do you know of","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"1527b0ce-8dd9-41c3-97bc-93098d633925":{"id_":"1527b0ce-8dd9-41c3-97bc-93098d633925","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Ui8EECJCIPNS8U/RxTRCTkBBZEeD+TUlgb8oUkt0eh8=","metadata":{},"hash":"tW6+N2vScH+X6d6rCUDPWAYgINdEDtZiZwjgk20owPc="},"NEXT":{"nodeId":"937d0e68-fad5-4e34-992c-0fd75ba69998","metadata":{},"hash":"2CiimZ1b8x+Q7G28H2Ufchk5Iqu6/XC5x5dZCTz38xo="}},"hash":"P6UXVzzJpp1gGS72DrvlUbuGarVWjOE6IAfCCGtAjas=","text":"arXiv, April, 2023,J.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\r\nFigure 9: The diffusion path for Isabella Rodriguez’s Valentine’s Day party. A total of 12 agents heard about the party at Hobbs\r\nCafe by the end of the simulation. <name>? \" For example, when asked “Do you know of Maria Lopez?”,\r\nKlaus responded,“Yes, I know Maria Lopez. She is a student at Oak\r\nHill College who I am close friends with.”Once again, we confirm\r\nthat affirmative responses from agents are not hallucinations by\r\nexamining their memory stream. We ask this question once at the\r\nbeginning of the simulation and once at the end, and we consider a\r\npair of agents to have formed a relationship if they both know of\r\neach other. Then, to measure the formation of relationships, we use\r\nthe agents’ responses to form an undirected graph where the 25\r\nvertices (푉) represent the agents, and the edges (퐸) represent the\r\nmutual knowledge between the two connected vertices. Based on\r\nthis graph, we calculate the network density as휂=2∗|퐸|/|푉|(|푉|−\r\n1), where|푉|is the number of vertices, and|퐸|is the number of\r\nedges in the graph [1]. We report the increase in network density\r\nfrom the start of the simulation to its end. Finally, we expect that agents should be able to coordinate with\r\neach other. We study this coordination on group activities in the\r\ncontext of the Valentine’s Day party that Isabella is organizing. To\r\ncoordinate behavior, agents not only have to hear about the event\r\nbut also choose to act on it by planning to show up at the right\r\ntime and location. We report the number of agents who actually\r\nshowed up to the party after hearing about it. 7.1.2    Results.We observed evidence of the emergent outcomes\r\nacross all three cases.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"937d0e68-fad5-4e34-992c-0fd75ba69998":{"id_":"937d0e68-fad5-4e34-992c-0fd75ba69998","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Ui8EECJCIPNS8U/RxTRCTkBBZEeD+TUlgb8oUkt0eh8=","metadata":{},"hash":"tW6+N2vScH+X6d6rCUDPWAYgINdEDtZiZwjgk20owPc="},"PREVIOUS":{"nodeId":"1527b0ce-8dd9-41c3-97bc-93098d633925","metadata":{},"hash":"P6UXVzzJpp1gGS72DrvlUbuGarVWjOE6IAfCCGtAjas="}},"hash":"2CiimZ1b8x+Q7G28H2Ufchk5Iqu6/XC5x5dZCTz38xo=","text":"During the two-day simulation, the agents\r\nwho knew about Sam’s mayoral candidacy increased from one (4%)\r\nto eight (32%), and the agents who knew about Isabella’s party\r\nincreased from one (4%) to twelve (48%), completely without user\r\nintervention. None who claimed to know about the information\r\nhad hallucinated it. We also observed that the agent community\r\nformed new relationships during the simulation, with the network\r\ndensity increasing from 0.167 to 0.74. Out of the 453 agent responses\r\nregarding their awareness of other agents, 1.3% (n=6) were found to\r\nbe hallucinated. Lastly, we found evidence of coordination among\r\nthe agents for Isabella’s party. The day before the event, Isabella\r\nspent time inviting guests, gathering materials, and enlisting help\r\nto decorate the cafe. On Valentine’s Day, five out of the twelve\r\ninvited agents showed up at Hobbs cafe to join the party. We further inspected the seven agents who were invited to the\r\nparty but did not attend by engaging them in an interview. Three\r\ncited conflicts that prevented them from joining the party. For\r\nexample, Rajiv, a painter, explained that he was too busy:No, I\r\ndon’t think so. I’m focusing on my upcoming show, and I don’t really\r\nhave time to make any plans for Valentine’s Day.The remaining four\r\nagents expressed interest in attending the party when asked but\r\ndid not plan to come on the day of the party. 7.2  Boundaries and Errors\r\nWe conducted an inductive analysis of Smallville to examine the\r\nboundary conditions and erratic behavior of agents, identifying\r\nthree common modes of erratic behavior that future research could\r\naddress and improve upon. First, we found that synthesizing an\r\nincreasingly larger set of memory not only posed a challenge in","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"69fe04fb-4c61-4755-943e-c68d2647a386":{"id_":"69fe04fb-4c61-4755-943e-c68d2647a386","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"mudaD7UrVZVArwOFIj1APfMGVMRbYuKCjddiSbpdMQ4=","metadata":{},"hash":"o7E2iwmwrZaxMdM73E2UKX9wEVX3Jup4lIdWv2JpXfg="},"NEXT":{"nodeId":"6d136862-354e-4821-9d22-642f56e6e1db","metadata":{},"hash":"z4P0z4i5pSP2/owDJcp58PusRtO79rg6/l5svN+0tKM="}},"hash":"pgU66Uo6tK9p8q92125yD9Mep8JAsxBd04gop9GnNtQ=","text":"Generative AgentsarXiv, April, 2023,\r\nretrieving the most relevant pieces of information but also in de-\r\ntermining the appropriate space to execute an action, given the\r\nincreasing number of locations that the agent learned about. As a\r\nresult, some agents chose less typical locations for their actions,\r\npotentially making their behavior less believable over time. For\r\ninstance, while deciding where to have lunch, many initially chose\r\nthe cafe. However, as some agents learned about a nearby bar, they\r\nopted to go there instead for lunch, even though the bar was in-\r\ntended to be a get-together location for later in the day unless the\r\ntown had spontaneously developed an afternoon drinking habit. Second, we noticed erratic behaviors that were caused by misclas-\r\nsification of what is considered proper behavior, especially when\r\nthe physical norms of certain locations that are hard to convey\r\nin natural language did not percolate to the agents. For instance,\r\nthe college dorm has a bathroom that can only be occupied by\r\none person despite its name, but some agents assumed that the\r\nbathroom is for more than one person because dorm bathrooms\r\ntend to support more than one person concurrently and choose\r\nto enter it when there is another person inside. Likewise, agents\r\nin Smallville may not realize that certain places are closed after\r\ncertain hours and decide to still enter them. For instance, the stores\r\nin Smallville all close around 5 pm, but occasionally, a few agents\r\nenter the store after 5 pm, not understanding that the shop has\r\nalready closed. These issues could likely be addressed by adding\r\nthese norms to the state of the locations, for instance, by describing\r\nthe dorm bathroom as “one-person bathroom,” instead of a “dorm\r\nbathroom. ”\r\nFinally, we observed the possible effect of instruction tuning [78],\r\nwhich seemed to guide the behavior of the agents to be more polite\r\nand cooperative overall. As noted earlier in the paper, the dialogue\r\ngenerated by the agents could feel overly formal, as seen in Mei’s\r\nconversations with her husband John, where she often initiated the\r\nconversation with a formal greeting, followed by polite inquiries\r\nabout his day and ending withIt was good talking to you as always. Moreover, we observed that the instruction tuning also seemed to\r\nmake the agents overly cooperative with one another.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"6d136862-354e-4821-9d22-642f56e6e1db":{"id_":"6d136862-354e-4821-9d22-642f56e6e1db","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"mudaD7UrVZVArwOFIj1APfMGVMRbYuKCjddiSbpdMQ4=","metadata":{},"hash":"o7E2iwmwrZaxMdM73E2UKX9wEVX3Jup4lIdWv2JpXfg="},"PREVIOUS":{"nodeId":"69fe04fb-4c61-4755-943e-c68d2647a386","metadata":{},"hash":"pgU66Uo6tK9p8q92125yD9Mep8JAsxBd04gop9GnNtQ="},"NEXT":{"nodeId":"9f149c4d-b691-493a-bbf0-d5d18c7b6d12","metadata":{},"hash":"FJM5J3LZjVVivC5rgdXr7OAhxAO/DiuRfqjv+deauiY="}},"hash":"z4P0z4i5pSP2/owDJcp58PusRtO79rg6/l5svN+0tKM=","text":"For example,\r\nIsabella heard a wide range of suggestions and ideas to include\r\nin the Valentine’s Day party from other agents, such as hosting a\r\nShakespearean reading session or a professional networking event. Despite these ideas not aligning with her own interests and char-\r\nacteristics, she rarely said no. Over time, such interests of others\r\nshaped her own actual interest, and when asked if she liked English\r\nliterature, Isabella replied,Yes, I’m very interested in literature! I’ve\r\nalso been exploring ways to help promote creativity and innovation in\r\nmy community. 8  DISCUSSION\r\nIn this section, we reflect on applications, future work and limita-\r\ntions, and ethical and societal risks of generative agents. 8.1  Applications of Generative Agents\r\nGenerative agents have vast potential applications that extend be-\r\nyond the sandbox demonstration presented in this work. For in-\r\nstance, social simulacra have demonstrated the ability to create\r\nstateless personas that generate conversation threads in online\r\nforums for social prototyping [79]. With generative agents, we\r\ncan populate these forums, as well as behavior in virtual reality\r\nmetaverses [77] and even physical spaces as social robots [8] in\r\nthe future, if paired with multi-modal models. This opens up the\r\npossibility of creating even more powerful simulations of human\r\nbehavior to test and prototype social systems and theories, and to\r\ncreate new interactive experiences. Another application area is in the human-centered design pro-\r\ncess, similar to the intended applications of cognitive models such\r\nas GOMS [50] and the Keystroke Level Model [22]. Consider a gen-\r\nerative agent that models Sal, the protagonist in Mark Weiser’s\r\nfamous vignettes [101], based on her life patterns and interactions\r\nwith technology. In this scenario, the agent acts as a proxy for\r\nSal and learns plausible sets of behaviors and reflections that Sal\r\nmay exhibit based on her life. The agent can encode information\r\nsuch as when Sal wakes up, when she needs her first cup of coffee,\r\nand what her typical day looks like. Using this information, the\r\nagent can automatically brew coffee, help get the kids ready for\r\nschool, and adjust the ambient music and lighting to match Sal’s\r\nmood after a hard day at work.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"9f149c4d-b691-493a-bbf0-d5d18c7b6d12":{"id_":"9f149c4d-b691-493a-bbf0-d5d18c7b6d12","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"mudaD7UrVZVArwOFIj1APfMGVMRbYuKCjddiSbpdMQ4=","metadata":{},"hash":"o7E2iwmwrZaxMdM73E2UKX9wEVX3Jup4lIdWv2JpXfg="},"PREVIOUS":{"nodeId":"6d136862-354e-4821-9d22-642f56e6e1db","metadata":{},"hash":"z4P0z4i5pSP2/owDJcp58PusRtO79rg6/l5svN+0tKM="}},"hash":"FJM5J3LZjVVivC5rgdXr7OAhxAO/DiuRfqjv+deauiY=","text":"By utilizing generative agents as\r\nproxies for users, we can develop a deeper understanding of their\r\nneeds and preferences, resulting in more personalized and effective\r\ntechnological experiences. 8.2  Future Work and Limitations\r\nIn this work, we have presented a first instantiation of generative\r\nagents. Future research can expand on the modules of the proposed\r\ngenerative agent architecture outlined in this paper. The retrieval\r\nmodule, for example, could be enhanced to retrieve more relevant\r\ninformation given a context by fine-tuning the relevance, recency,\r\nand importance functions that form the retrieval function. Addition-\r\nally, efforts can be made to improve the architecture’s performance,\r\nmaking it more cost-effective. The present study required substan-\r\ntial time and resources to simulate 25 agents for two days, costing\r\nthousands of dollars in token credit and taking multiple days to com-\r\nplete. To enhance real-time interactivity, future work can explore\r\nparallelizing agents. Furthermore, with advances in underlying\r\nmodels, we expect improvements in the agents’ performance. The evaluation of generative agents’ behavior in this study was\r\nlimited to a relatively short timescale, and future research should\r\naim to observe their behavior over an extended period to gain a\r\nmore comprehensive understanding of their capabilities and lim-\r\nitations. Varying and contrasting the underlying models, as well\r\nas the hyperparameters used for the agents during future simu-\r\nlations, could provide valuable insights into the impact of these\r\nfactors on the agents’ behavior. Additionally, given the known bi-\r\nases of language models, it is possible that generative agents may\r\noutput behavior or stereotypes that reflect bias. To mitigate this,\r\nfurther work on value alignment will be necessary. Furthermore,\r\nas with many large language models, generative agents may fail\r\nto generate believable behavior for some subpopulations, particu-\r\nlarly marginalized populations, due to data deserts. We also have\r\nlimited knowledge of the robustness of generative agents. They\r\nmay be vulnerable to prompt hacking, memory hacking—where\r\na carefully crafted conversation could convince an agent of the\r\nexistence of a past event that never occurred—and hallucination,\r\namong other things. Future research can more comprehensively","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"5452075f-a7d0-464b-8850-ec1ec6b7e577":{"id_":"5452075f-a7d0-464b-8850-ec1ec6b7e577","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Q5wSlTTntb+biLJn8e5fRRG0T+mQs2Z99lbErSb6JQk=","metadata":{},"hash":"OyV6pdzVscQhmRqFOJ6ip/gHl94NgQXPw1ANg6USSH8="},"NEXT":{"nodeId":"f98abf3c-cabb-4bf9-8acc-9eb4b9591f60","metadata":{},"hash":"6wtSvN6wE3/KGw64aw7gly8cEnnoGbZM+1ajsdAkbbs="}},"hash":"NR0N9iiZxn/ztnpA3FnE2xqMaK0awQwej/jsDHsHYz8=","text":"arXiv, April, 2023,J.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\r\ntest these robustness issues, and as large language models become\r\nmore resilient to such attacks, generative agents can adopt similar\r\nmitigations. 8.3  Ethics and Societal Impact\r\nGenerative  agents,  while  offering  new  possibilities  for  human-\r\ncomputer interaction, also raise important ethical concerns that\r\nmust be addressed. One risk is people forming parasocial relation-\r\nships with generative agents even when such relationships may\r\nnot be appropriate. Despite being aware that generative agents\r\nare computational entities, users may anthropomorphize them or\r\nattach human emotions to them [42,83]. To mitigate this risk, we\r\npropose two principles. First, generative agents should explicitly\r\ndisclose their nature as computational entities. Second, developers\r\nof generative agents must ensure that the agents, or the underlying\r\nlanguage models, be value-aligned so that they do not engage in\r\nbehaviors that would be inappropriate given the context, e.g., to\r\nreciprocate confessions of love. A second risk is the impact of errors. For example, if a ubiquitous\r\ncomputing application makes the wrong inference about a user’s\r\ngoals based on generative agent predictions, it could produce an-\r\nnoyance at best and outright harm at worst. In our instantiation\r\nof generative agents, we mitigate these risks by focusing on an\r\ninteractive video game environment, where such harms are un-\r\nlikely. However, in other application domains, it will be important\r\nto follow best practices in human-AI design [4,107] to understand\r\nerrors and how they might percolate into the user experience. Third, generative agents may exacerbate existing risks associ-\r\nated with generative AI, for example deepfakes, misinformation\r\ngeneration, and tailored persuasion. To mitigate this risk, we sug-\r\ngest that platforms hosting generative agents maintain an audit log\r\nof the inputs and generated outputs, so that it is possible to detect,\r\nverify, and intervene against malicious use.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"f98abf3c-cabb-4bf9-8acc-9eb4b9591f60":{"id_":"f98abf3c-cabb-4bf9-8acc-9eb4b9591f60","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Q5wSlTTntb+biLJn8e5fRRG0T+mQs2Z99lbErSb6JQk=","metadata":{},"hash":"OyV6pdzVscQhmRqFOJ6ip/gHl94NgQXPw1ANg6USSH8="},"PREVIOUS":{"nodeId":"5452075f-a7d0-464b-8850-ec1ec6b7e577","metadata":{},"hash":"NR0N9iiZxn/ztnpA3FnE2xqMaK0awQwej/jsDHsHYz8="},"NEXT":{"nodeId":"fc922669-63b1-4451-97d5-1fdae20ceeac","metadata":{},"hash":"NSV7NCZPbJ2yhm8XvinviPcFnKwG0E+aHA1797yRAa4="}},"hash":"6wtSvN6wE3/KGw64aw7gly8cEnnoGbZM+1ajsdAkbbs=","text":"While logging will not\r\ndirectly stop such use, and this cannot stop motivated actors that\r\nbuild their own generative agent infrastructures, we suggest that\r\nthe disclosure risk would reduce such actors’ likelihood of engaging\r\nin this behavior, and building this architecture oneself can take time\r\n(in our case, roughly a year). A fourth risk is of over-reliance: that developers or designers\r\nmight use generative agents and displace the role of humans and\r\nsystem stakeholders in the design process [79]. We suggest that\r\ngenerative agents should never be a substitute for real human input\r\nin studies and design processes. Instead, they should be used to\r\nprototype ideas in the early stages of design when gathering partic-\r\nipants may be challenging or when testing theories that are difficult\r\nor risky to test with real human participants. By adhering to these\r\nprinciples, we can ensure that the deployment of generative agents\r\nin the wild is ethical and socially responsible. 9  CONCLUSION\r\nThis paper introduces generative agents, interactive computational\r\nagents that simulate human behavior. We describe an architec-\r\nture for generative agents that provides a mechanism for storing\r\na comprehensive record of an agent’s experiences, deepening its\r\nunderstanding of itself and the environment through reflection,\r\nand retrieving a compact subset of that information to inform the\r\nagent’s actions. We then demonstrate the potential of generative\r\nagents by manifesting them as non-player characters in a Sims-style\r\ngame world and simulating their lives in it. Evaluations suggest that\r\nour architecture creates believable behavior. Going forward, we\r\nsuggest that generative agents can play roles in many interactive\r\napplications ranging from design tools to social computing systems\r\nto immersive environments. REFERENCES\r\n[1]Robert  Ackland,  Jamsheed  Shorish,  Paul  Thomas,  and  Lexing  Xie. 2013.How dense is a network? http://users.cecs.anu.edu.au/~xlx/teaching/css2013/\r\nnetwork-density.html.[2]Eytan Adar, Mira Dontcheva, and Gierad Laput. 2014. CommandSpace: Modeling\r\nthe Relationships between Tasks, Descriptions and Features. InProceedings ofthe 27th Annual ACM Symposium on User Interface Software and Technology\r\n(Honolulu, Hawaii, USA)(UIST ’14).","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"fc922669-63b1-4451-97d5-1fdae20ceeac":{"id_":"fc922669-63b1-4451-97d5-1fdae20ceeac","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Q5wSlTTntb+biLJn8e5fRRG0T+mQs2Z99lbErSb6JQk=","metadata":{},"hash":"OyV6pdzVscQhmRqFOJ6ip/gHl94NgQXPw1ANg6USSH8="},"PREVIOUS":{"nodeId":"f98abf3c-cabb-4bf9-8acc-9eb4b9591f60","metadata":{},"hash":"6wtSvN6wE3/KGw64aw7gly8cEnnoGbZM+1ajsdAkbbs="},"NEXT":{"nodeId":"ba3c0f6c-7210-464b-a88d-e9fcd9f55162","metadata":{},"hash":"Cu9pKoouAQfCNk6mN07n72D/uwlWF3gCf071x+/EVBA="}},"hash":"NSV7NCZPbJ2yhm8XvinviPcFnKwG0E+aHA1797yRAa4=","text":"Association for Computing Machinery, NewYork, NY, USA, 167–176. https://doi.org/10.1145/2642918.2647395\r\n[3]Saleema Amershi, Maya Cakmak, William Bradley Knox, and Todd Kulesza.2014. Power to the people: The role of humans in interactive machine learning. AI Magazine35, 4 (2014), 105–120.[4]Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira\r\nNushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul N Bennett, Kori Inkpen,et al.2019. Guidelines for human-AI interaction. InProceedings of the 2019 chi\r\nconference on human factors in computing systems. 1–13.[5]John R. Anderson. 1993.Rules of the Mind. Lawrence Erlbaum Associates,\r\nHillsdale, NJ.[6]  Electronic Arts. 2009. The Sims 3. Video game. [7]Ruth Aylett. 1999. Narrative in virtual environments—towards emergent narra-tive. InNarrative Intelligence: Papers from the AAAI Fall Symposium (Technical\r\nReport FS-99-01). AAAI Press, 83–86.[8]Christoph Bartneck and Jodi Forlizzi. 2004. A design-centered framework for\r\nsocial human-robot interaction. InProceedings of the 13th IEEE InternationalWorkshop on Robot and Human Interactive Communication (RO-MAN’04). 591–\r\n594. https://doi.org/10.1109/ROMAN.2004.1374827[9]Joseph Bates. 1994. The Role of Emotion in Believable Agents.Commun. ACM\r\n37, 7 (1994), 122–125.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"ba3c0f6c-7210-464b-a88d-e9fcd9f55162":{"id_":"ba3c0f6c-7210-464b-a88d-e9fcd9f55162","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Q5wSlTTntb+biLJn8e5fRRG0T+mQs2Z99lbErSb6JQk=","metadata":{},"hash":"OyV6pdzVscQhmRqFOJ6ip/gHl94NgQXPw1ANg6USSH8="},"PREVIOUS":{"nodeId":"fc922669-63b1-4451-97d5-1fdae20ceeac","metadata":{},"hash":"NSV7NCZPbJ2yhm8XvinviPcFnKwG0E+aHA1797yRAa4="},"NEXT":{"nodeId":"f3972287-1293-4fe6-ad31-2ab8af36816b","metadata":{},"hash":"pDYcP+Z85U27tDe8L3ov0kJBLdt4466lynG85gxTECM="}},"hash":"Cu9pKoouAQfCNk6mN07n72D/uwlWF3gCf071x+/EVBA=","text":"ACM\r\n37, 7 (1994), 122–125. https://doi.org/10.1145/176789.176803[10]Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemysław\r\nDębiak, Christy Dennison, David Farhi, Quirin Fischer, Shariq Hashme, ChrisHesse, Rafal Józefowicz, Scott Gray, Catherine Olsson, Jakub Pachocki, Michael\r\nPetrov, Henrique P. d.O. Pinto, Jonathan Raiman, Tim Salimans, Jeremy Schlatter,Jonas Schneider, Szymon Sidor, Ilya Sutskever, Jie Tang, Filip Wolski, and Susan\r\nZhang. 2019. Dota 2 with Large Scale Deep Reinforcement Learning.arXivpreprint arXiv:1912.06680(2019). [11]Marcel  Binz  and  Eric  Schulz. 2023. Using  cognitive  psychology  to  under-stand GPT-3.Proceedings of the National Academy of Sciences120, 6 (2023),\r\ne2218523120.[12]  BioWare. 2007. Mass Effect. Video game. [13]Woody Bledsoe. 1986. I had a dream: AAAI presidential address.AI Magazine7,1 (1986), 57–61. [14]Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, and et al. 2022. On theOpportunities and Risks of Foundation Models. arXiv:2108.07258 [cs.LG]\r\n[15]Michael Brenner. 2010. Creating dynamic story plots with continual multiagentplanning. InProceedings of the 24th AAAI Conference on Artificial Intelligence. [16]Rodney A. Brooks, Cynthia Breazeal, Marko Marjanovic, Brian Scassellati, andMatthew Williamson. 2000. The Cog Project: Building a Humanoid Robot. In\r\nComputation for Metaphors, Analogy, and Agents (Lecture Notes on ArtificialIntelligence, 1562), Chrystopher Nehaniv (Ed.).","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"f3972287-1293-4fe6-ad31-2ab8af36816b":{"id_":"f3972287-1293-4fe6-ad31-2ab8af36816b","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Q5wSlTTntb+biLJn8e5fRRG0T+mQs2Z99lbErSb6JQk=","metadata":{},"hash":"OyV6pdzVscQhmRqFOJ6ip/gHl94NgQXPw1ANg6USSH8="},"PREVIOUS":{"nodeId":"ba3c0f6c-7210-464b-a88d-e9fcd9f55162","metadata":{},"hash":"Cu9pKoouAQfCNk6mN07n72D/uwlWF3gCf071x+/EVBA="}},"hash":"pDYcP+Z85U27tDe8L3ov0kJBLdt4466lynG85gxTECM=","text":"Springer-Verlag, Berlin, 52–87. [17]Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\r\nAskell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter,\r\nChristopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, BenjaminChess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya\r\nSutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners.arXiv:2005.14165 [cs.CL]\r\n[18]Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, EricHorvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. 2023. Sparks of artificial general intelligence: Early experiments with gpt-4.arXiv preprint arXiv:2303.12712(2023). [19]Robin Burkinshaw. 2009. Alice and Kev: The Story of Being Homeless in TheSims 3. [20]Chris Callison-Burch, Gaurav Singh Tomar, Lara Martin, Daphne Ippolito, SumaBailis, and David Reitter. 2022. Dungeons and Dragons as a Dialog Challenge for\r\nArtificial Intelligence. InProceedings of the 2022 Conference on Empirical Methods","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"6c2c9a4f-2c75-4ec9-92a7-8ead9977a37d":{"id_":"6c2c9a4f-2c75-4ec9-92a7-8ead9977a37d","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Cf4YXeXUzeEKOoFr/LnnrpFAA5qntNrNe4jAKxovd1Y=","metadata":{},"hash":"LblX6EsJISjkxQJ8dWgHhsb7/3Z01arxVfR4lqnuyh4="},"NEXT":{"nodeId":"b0666028-2ba1-4668-9d10-7d6e00cc742b","metadata":{},"hash":"yP5/D0XgVK5OEHp4pvsK6Ir3N7Lu4GyXbbJrLHIKPe8="}},"hash":"o1rFA8wJpGycd3UCnS9ceUPWRncA5BAUKeUIH8tjyAQ=","text":"Generative AgentsarXiv, April, 2023,\r\nin Natural Language Processing. Association for Computational Linguistics, AbuDhabi, United Arab Emirates, 9379–9393. https://aclanthology.org/2022.emnlp-\r\nmain.637[21]SK Card, TP Moran, and A Newell. 1983. The psychology of human-computer\r\ninteraction. (1983).[22]Stuart K Card, Thomas P Moran, and Newell Allen. 1980. The keystroke-\r\nlevel  model  for  user  performance  time  with  interactive  systems.Com-mun. ACM23,  7  (1980),  396–410. https://doi.org/10.1145/358886.358895\r\narXiv:https://doi.org/10.1145/358886.358895[23]Alex Champandard. 2012. Tutorial presentation. InIEEE Conference on Compu-\r\ntational Intelligence and Games.[24]Dong kyu Choi, Tolga Konik, Negin Nejati, Chunki Park, and Pat Langley. 2021. A Believable Agent for First-Person Shooter Games. InProceedings of the AAAIConference on Artificial Intelligence and Interactive Digital Entertainment, Vol. 3. 71–73.[25]Anind K Dey. 2001. Understanding and using context.Personal and ubiquitous\r\ncomputing5 (2001), 4–7.[26]Kevin Dill and L Martin. 2011. A Game AI Approach to Autonomous Con-\r\ntrol of Virtual Characters. InProceedings of the Interservice/Industry Training,Simulation, and Education Conference (I/ITSEC’11). Orlando, FL, USA. [27]David Easley and Jon Kleinberg. 2010.Networks, crowds, and markets: Reasoningabout a highly connected world. Cambridge university press. [28]Arpad E Elo. 1967. The Proposed USCF Rating System, Its Development, Theory,and Applications.Chess LifeXXII, 8 (August 1967), 242–247. [29]Jerry Alan Fails and Dan R Olsen Jr. 2003. Interactive machine learning. InProceedings of the 8th international conference on Intelligent user interfaces.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"b0666028-2ba1-4668-9d10-7d6e00cc742b":{"id_":"b0666028-2ba1-4668-9d10-7d6e00cc742b","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Cf4YXeXUzeEKOoFr/LnnrpFAA5qntNrNe4jAKxovd1Y=","metadata":{},"hash":"LblX6EsJISjkxQJ8dWgHhsb7/3Z01arxVfR4lqnuyh4="},"PREVIOUS":{"nodeId":"6c2c9a4f-2c75-4ec9-92a7-8ead9977a37d","metadata":{},"hash":"o1rFA8wJpGycd3UCnS9ceUPWRncA5BAUKeUIH8tjyAQ="},"NEXT":{"nodeId":"362ede1b-05e2-4bad-a213-f47b5bfcda26","metadata":{},"hash":"pbAywXrGFtRbiKjiccU6zRi+QDDj+rp1JAz5cUUnpIw="}},"hash":"yP5/D0XgVK5OEHp4pvsK6Ir3N7Lu4GyXbbJrLHIKPe8=","text":"Interactive machine learning. InProceedings of the 8th international conference on Intelligent user interfaces. ACM,\r\n39–45.[30]Ethan Fast, William McGrath, Pranav Rajpurkar, and Michael S Bernstein. 2016. Augur: Mining human behaviors from fiction to power interactive systems. InProceedings of the 2016 CHI Conference on Human Factors in Computing Systems. 237–247.[31]Rebecca Fiebrink and Perry R Cook. 2010. The Wekinator: a system for real-time,\r\ninteractive machine learning in music. InProceedings of The Eleventh Interna-tional Society for Music Information Retrieval Conference (ISMIR 2010)(Utrecht),\r\nVol. 3. Citeseer, 2–1.[32]  Uwe Flick. 2009.An Introduction to Qualitative Research. SAGE. [33]James Fogarty, Desney Tan, Ashish Kapoor, and Simon Winder. 2008. CueFlik:Interactive Concept Learning in Image Search. InProceedings of the SIGCHI\r\nConference on Human Factors in Computing Systems(Florence, Italy)(CHI ’08).Association for Computing Machinery, New York, NY, USA, 29–38. https:\r\n//doi.org/10.1145/1357054.1357061[34]Adam Fourney, Richard Mann, and Michael Terry. 2011. Query-feature graphs:\r\nbridging user vocabulary and system functionality. InProceedings of the ACMSymposium on User Interface Software and Technology (UIST)(Santa Barbara,\r\nCalifornia, USA). ACM.[35]Tom  Francis. 2010.The Minecraft Experiment, day 1: Chasing Water-\r\nfalls. http://www.pcgamer.com/2010/11/20/the-minecraft-experiment-day-1-chasing-waterfalls/\r\n[36]Jonas Freiknecht and Wolfgang Effelsberg. 2020. Procedural Generation ofInteractive Stories using Language Models. InInternational Conference on the\r\nFoundations of Digital Games (FDG ’20). ACM, Bugibba, Malta, 8. https://doi.org/10.1145/3402942.3409599\r\n[37]Tianyu Gao, Adam Fisch, and Danqi Chen. 2020.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"362ede1b-05e2-4bad-a213-f47b5bfcda26":{"id_":"362ede1b-05e2-4bad-a213-f47b5bfcda26","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Cf4YXeXUzeEKOoFr/LnnrpFAA5qntNrNe4jAKxovd1Y=","metadata":{},"hash":"LblX6EsJISjkxQJ8dWgHhsb7/3Z01arxVfR4lqnuyh4="},"PREVIOUS":{"nodeId":"b0666028-2ba1-4668-9d10-7d6e00cc742b","metadata":{},"hash":"yP5/D0XgVK5OEHp4pvsK6Ir3N7Lu4GyXbbJrLHIKPe8="},"NEXT":{"nodeId":"a7c2c2a8-c93f-48f9-a95c-7b67c442169a","metadata":{},"hash":"tyXsigmkyENNeix7AxKPPExPDHwB+Uh7yeqZJJov5EM="}},"hash":"pbAywXrGFtRbiKjiccU6zRi+QDDj+rp1JAz5cUUnpIw=","text":"2020. Making Pre-trained LanguageModels Better Few-shot Learners.CoRR abs/2012.15723(2020). arXiv:2012.15723\r\nhttps://arxiv.org/abs/2012.15723[38]Perttu Hämäläinen, Mikke Tavast, and Anton Kunnari. 2023. Evaluating Large\r\nLanguage Models in Generating Synthetic HCI Research Data: a Case Study. InProceedings of the 2023 CHI Conference on Human Factors in Computing Systems. ACM.[39]Matthew Hausknecht, Prithviraj Ammanabrolu, Marc-Alexandre Cote, and\r\nXinyu Yuan. 2020. Interactive Fiction Games: A Colossal Adventure. InPro-ceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 7903–7910. https://doi.org/10.1609/aaai.v34i05.6297[40]Chris Hecker. 2011.My Liner Notes for Spore. http://chrishecker.com/My_liner_\r\nnotes_for_spore[41]Ralf  Herbrich,  Tom  Minka,  and  Thore  Graepel. 2006. TrueSkill™:  A\r\nBayesian  Skill  Rating  System. InAdvances in Neural Information Pro-cessing Systems,  B. Schölkopf,  J. Platt,  and  T. Hoffman  (Eds.),  Vol. 19. MIT   Press. https://proceedings.neurips.cc/paper_files/paper/2006/file/f44ee263952e65b3610b8ba51229d1f9-Paper.pdf\r\n[42]Douglas Hofstadter. 1995.Fluid concepts and creative analogies: computer modelsof the fundamental mechanisms of thought. Basic Books. [43]James D. Hollan, Edwin L. Hutchins, and Louis Weitzman. 1984. STEAMER: AnInteractive Inspectable Simulation-Based Training System.AI Magazine5, 2\r\n(1984), 23–36.[44]S Holm. 1979.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"a7c2c2a8-c93f-48f9-a95c-7b67c442169a":{"id_":"a7c2c2a8-c93f-48f9-a95c-7b67c442169a","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Cf4YXeXUzeEKOoFr/LnnrpFAA5qntNrNe4jAKxovd1Y=","metadata":{},"hash":"LblX6EsJISjkxQJ8dWgHhsb7/3Z01arxVfR4lqnuyh4="},"PREVIOUS":{"nodeId":"362ede1b-05e2-4bad-a213-f47b5bfcda26","metadata":{},"hash":"pbAywXrGFtRbiKjiccU6zRi+QDDj+rp1JAz5cUUnpIw="},"NEXT":{"nodeId":"f7abc701-6dcf-4005-913d-22090c434649","metadata":{},"hash":"fsf4GawVI6gSLOx8Dk6A95QHSV/NYO8F9F2DpaHdCfY="}},"hash":"tyXsigmkyENNeix7AxKPPExPDHwB+Uh7yeqZJJov5EM=","text":"1979. A simple sequentially rejective multiple test procedure.Scandi-\r\nnavian Journal of Statistics6, 2 (1979), 65–70. https://doi.org/notspecified\r\n[45]John J. Horton. 2023. Large Language Models as Simulated Economic Agents:What Can We Learn from Homo Silicus? arXiv:2301.07543 [econ.GN]\r\n[46]Eric Horvitz. 1999. Principles of mixed-initiative user interfaces. InProceedingsof the SIGCHI conference on Human Factors in Computing Systems. 159–166. [47]Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence,Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, Pierre Ser-\r\nmanet, Noah Brown, Tomas Jackson, Linda Luu, Sergey Levine, Karol Hausman,and Brian Ichter. 2022. Inner Monologue: Embodied Reasoning through Planning\r\nwith Language Models. arXiv:2207.05608 [cs.RO][48]Kristen Ibister and Clifford Nass. 2000. Consistency of personality in interactive\r\ncharacters: verbal cues, non-verbal cues, and user characteristics.InternationalJournal of Human-Computer Studies52, 1 (2000), 65–80. [49]Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach,Michael Terry, and Carrie J Cai. 2022. PromptMaker: Prompt-Based Prototyping\r\nwith Large Language Models. InExtended Abstracts of the 2022 CHI Conferenceon Human Factors in Computing Systems(New Orleans, LA, USA)(CHI EA ’22). Association for Computing Machinery, New York, NY, USA, Article 35, 8 pages.https://doi.org/10.1145/3491101.3503564\r\n[50]Bonnie E John and David E Kieras. 1996.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"f7abc701-6dcf-4005-913d-22090c434649":{"id_":"f7abc701-6dcf-4005-913d-22090c434649","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Cf4YXeXUzeEKOoFr/LnnrpFAA5qntNrNe4jAKxovd1Y=","metadata":{},"hash":"LblX6EsJISjkxQJ8dWgHhsb7/3Z01arxVfR4lqnuyh4="},"PREVIOUS":{"nodeId":"a7c2c2a8-c93f-48f9-a95c-7b67c442169a","metadata":{},"hash":"tyXsigmkyENNeix7AxKPPExPDHwB+Uh7yeqZJJov5EM="},"NEXT":{"nodeId":"f6aba677-1aca-4ddf-b74c-1d2dd06f6a7c","metadata":{},"hash":"0nneOgSW5/wYSSyIaZo2eFlsrnL//nG2U4LnHyD+CSA="}},"hash":"fsf4GawVI6gSLOx8Dk6A95QHSV/NYO8F9F2DpaHdCfY=","text":"1996. The GOMS family of user interfaceanalysis techniques: Comparison and contrast.ACM Transactions on Computer-\r\nHuman Interaction (TOCHI)3, 4 (1996), 320–351.[51]Randolph M Jones, John E Laird, Paul E Nielsen, Karen J Coulter, Patrick Kenny,\r\nand Frank V Koss. 1999. Automated Intelligent Pilots for Combat Flight Simula-tion.AI Magazine20, 1 (1999), 27–42. [52]Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang,Christopher  Potts,  and  Matei  Zaharia. 2023. Demonstrate-Search-Predict:\r\nComposing  retrieval  and  language  models  for  knowledge-intensive  NLP.arXiv:2212.14024 [cs.CL]\r\n[53]Bjoern Knafla. 2011.Introduction to Behavior Trees. http://bjoernknafla.com/introduction-to-behavior-trees\r\n[54]Ranjay   Krishna,   Donsuk   Lee,   Li   Fei-Fei,   and   Michael   S. Bernstein.2022. Socially   situated   artificial   intelligence   enables   learning   from\r\nhuman  interaction.Proceedings of the National Academy of Sciences119,   39   (2022),   e2115730119. https://doi.org/10.1073/pnas.2115730119\r\narXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.2115730119[55]William H Kruskal and WA Wallis. 1952. Use of ranks in one-criterion variance\r\nanalysis.J. Amer. Statist. Assoc.47, 260 (1952), 583–621. https://doi.org/10.1080/01621459.1952.10483441\r\n[56]Phaser Labs. no date provided. Welcome to Phaser 3. https://phaser.io/phaser3.Accessed on: 2023-04-03. [57]John Laird. 2001. It Knows What You’re Going To Do: Adding Anticipation to aQuakebot.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"f6aba677-1aca-4ddf-b74c-1d2dd06f6a7c":{"id_":"f6aba677-1aca-4ddf-b74c-1d2dd06f6a7c","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Cf4YXeXUzeEKOoFr/LnnrpFAA5qntNrNe4jAKxovd1Y=","metadata":{},"hash":"LblX6EsJISjkxQJ8dWgHhsb7/3Z01arxVfR4lqnuyh4="},"PREVIOUS":{"nodeId":"f7abc701-6dcf-4005-913d-22090c434649","metadata":{},"hash":"fsf4GawVI6gSLOx8Dk6A95QHSV/NYO8F9F2DpaHdCfY="},"NEXT":{"nodeId":"d3a78066-c28b-437b-841d-9ae345a8e99e","metadata":{},"hash":"gDajokdKM0mqK3mhUunXbS+xE9Aq/fbXDh4P/L8ZdsY="}},"hash":"0nneOgSW5/wYSSyIaZo2eFlsrnL//nG2U4LnHyD+CSA=","text":"It Knows What You’re Going To Do: Adding Anticipation to aQuakebot. InProceedings of the 2001 Workshop on Intelligent Cinematography\r\nand Editing. 63–69.[58]John Laird and Michael VanLent. 2001. Human-Level AI’s Killer Application:\r\nInteractive Computer Games.AI Magazine22, 2 (2001), 15. https://doi.org/10.1609/aimag.v22i2.1558\r\n[59]John E. Laird. 2000. It Knows What You’re Going To Do: Adding Anticipationto a QUAKEBOT. InPapers from the AAAI 2000 Spring Symposium on Artificial\r\nIntelligence and Interactive Entertainment (Technical Report SS-00-02). AAAIPress, 41–50. [60]  John E. Laird. 2012.The Soar Cognitive Architecture. MIT Press.[61]John E. Laird, Christian Lebiere, and Paul S. Rosenbloom. 2017. A Standard Model\r\nof the Mind: Toward a Common Computational Framework across ArtificialIntelligence, Cognitive Science, Neuroscience, and Robotics.AI Magazine38, 1\r\n(2017), 13–26.[62]Michelle S Lam, Zixian Ma, Anne Li, Izequiel Freitas, Dakuo Wang, James A\r\nLanday, and Michael S Bernstein. 2023. Model Sketching: Centering Conceptsin Early-Stage Machine Learning Model Design.Proceedings of the SIGCHI\r\nConference on Human Factors in Computing Systems.[63]Pat Langley, Dongkyu Choi, and Seth Rogers. n.d..Interleaving Learning, Problem\r\nSolving, and Execution in the Icarus Architecture. Technical Report. StanfordUniversity, Center for the Study of Language and Information. [64]Jason Linder, Gierad Laput, Mira Dontcheva, Gregg Wilensky, Walter Chang,Aseem Agarwala, and Eytan Adar. 2013. PixelTone: A Multimodal Interface for\r\nImage Editing. InCHI ’13 Extended Abstracts on Human Factors in ComputingSystems(Paris, France)(CHI EA ’13).","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"d3a78066-c28b-437b-841d-9ae345a8e99e":{"id_":"d3a78066-c28b-437b-841d-9ae345a8e99e","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"Cf4YXeXUzeEKOoFr/LnnrpFAA5qntNrNe4jAKxovd1Y=","metadata":{},"hash":"LblX6EsJISjkxQJ8dWgHhsb7/3Z01arxVfR4lqnuyh4="},"PREVIOUS":{"nodeId":"f6aba677-1aca-4ddf-b74c-1d2dd06f6a7c","metadata":{},"hash":"0nneOgSW5/wYSSyIaZo2eFlsrnL//nG2U4LnHyD+CSA="}},"hash":"gDajokdKM0mqK3mhUunXbS+xE9Aq/fbXDh4P/L8ZdsY=","text":"Association for Computing Machinery,\r\nNew York, NY, USA, 2829–2830. https://doi.org/10.1145/2468356.2479533[65]Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and\r\nWeizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?CoRRabs/2101.06804(2021). arXiv:2101.06804  https://arxiv.org/abs/2101.06804\r\n[66]Vivian Liu, Han Qiao, and Lydia Chilton. 2022. Opal: Multimodal Image Gener-ation for News Illustration. InProceedings of the 35th Annual ACM Symposium\r\non User Interface Software and Technology. 1–17.[67]Pattie Maes. 1995. Artificial Life Meets Entertainment: Lifelike Autonomous\r\nAgents.Commun. ACM38, 11 (nov 1995), 108–114. https://doi.org/10.1145/219717.219808\r\n[68]Josh McCoy, Michael Mateas, and Noah Wardrip-Fruin. 2009. Comme il Faut:A System for Simulating Social Games Between Autonomous Characters. In","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"b5c9d0c4-7ec4-4234-a288-229ebc71a892":{"id_":"b5c9d0c4-7ec4-4234-a288-229ebc71a892","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"s3ONVQ7SDkJUXOaJ6FDwDVyub3zRe2GAHP6spNxdRp8=","metadata":{},"hash":"q0e1v5NbZUvadhfW90v/MCOZS61z4CYKg95EeOTBPAY="},"NEXT":{"nodeId":"8f0d08be-33ef-4f1c-b119-7f67704cc5ba","metadata":{},"hash":"Z8axe7l/iUZ/EnC4U5KV9Qa3Ojzi4rOEgL2eKv92HeM="}},"hash":"KoA25+p8beykib4jA+NekPYuQNhjuH5ShBDJWnZ36tE=","text":"arXiv, April, 2023,J.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\r\nProceedings of the 7th International Conference on Digital Arts and Culture. 87–94.[69]Josh McCoy, Mike Treanor, Ben Samuel, Michael Mateas, and Noah Wardrip-\r\nFruin. 2011. Prom Week: Social Physics as Gameplay. InProceedings of the6th International Conference on Foundations of Digital Games (FDG’11). ACM,\r\nBordeaux, France, 70–77. https://doi.org/10.1145/2159365.2159377[70]Josh McCoy, Mike Treanor, Ben Samuel, Anna Reed, Michael Mateas, and Noah\r\nWardrip-Fruin. 2012. Prom Week. InProceedings of the 7th International Confer-ence on Foundations of Digital Games (FDG’12). ACM, Raleigh, NC, USA, 1–8. https://doi.org/10.1145/2282338.2282340[71]Josh McCoy, Mike Treanor, Ben Samuel, Noah Wardrip-Fruin, and Michael\r\nMateas. 2011. Comme il faut: A System for Authoring Playable Social Models.InProceedings of the AAAI Conference on Artificial Intelligence and Interactive\r\nDigital Entertainment (AIIDE’11). AAAI, Stanford, CA, USA, 38–43.[72]Marvin Minsky and Seymour Papert. 1970. Draft of a proposal to ARPA for\r\nresearch on artificial intelligence at MIT, 1970–71.[73]Shohei Miyashita, Xinyu Lian, Xiao Zeng, Takashi Matsubara, and Kuniaki\r\nUehara. 2017. Developing Game AI Agent Behaving Like Human by MixingReinforcement Learning and Supervised Learning. InProceedings of the 18th\r\nIEEE/ACIS International Conference on Software Engineering, Artificial Intelligence,Networking and Parallel/Distributed Computing (SNPD). Kanazawa, Japan, 153–\r\n158.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"8f0d08be-33ef-4f1c-b119-7f67704cc5ba":{"id_":"8f0d08be-33ef-4f1c-b119-7f67704cc5ba","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"s3ONVQ7SDkJUXOaJ6FDwDVyub3zRe2GAHP6spNxdRp8=","metadata":{},"hash":"q0e1v5NbZUvadhfW90v/MCOZS61z4CYKg95EeOTBPAY="},"PREVIOUS":{"nodeId":"b5c9d0c4-7ec4-4234-a288-229ebc71a892","metadata":{},"hash":"KoA25+p8beykib4jA+NekPYuQNhjuH5ShBDJWnZ36tE="},"NEXT":{"nodeId":"86a3746b-f498-486a-ba30-710e9adf10f3","metadata":{},"hash":"5gObLMrwi6SST/m6x1jzyEJmX75umPAf8sB+KTn9y4U="}},"hash":"Z8axe7l/iUZ/EnC4U5KV9Qa3Ojzi4rOEgL2eKv92HeM=","text":"Kanazawa, Japan, 153–\r\n158. https://doi.org/10.1109/SNPD.2017.8023884[74]Alexander Nareyek. 2007. Game AI is dead. Long live game AI!IEEE Intelligent\r\nSystems22, 1 (2007), 9–11.[75]Allen Newell. 1990.Unified Theories of Cognition. Harvard University Press,\r\nCambridge, Massachusetts.[76]OpenAI. no date provided. Introducing ChatGPT. https://openai.com/blog/\r\nchatgpt. Accessed on: 2023-04-03.[77]Kyle Orland. 2021. So what is ’the metaverse’, exactly?Ars Technica(7 November\r\n2021). arXiv:2111.04169  https://arstechnica.com/gaming/2021/11/so-what-is-the-metaverse-exactly/\r\n[78]Long  Ouyang,  Jeff  Wu,  Xu  Jiang,  Diogo  Almeida,  Carroll  L. Wainwright,Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray,\r\nJohn  Schulman,  Jacob  Hilton,  Fraser  Kelton,  Luke  Miller,  Maddie  Simens,Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback.arXiv:2203.02155 [cs.CL]\r\n[79]Joon Sung Park, Lindsay Popowski, Carrie J. Cai, Meredith Ringel Morris, PercyLiang, and Michael S. Bernstein. 2022. Social Simulacra: Creating Populated\r\nPrototypes for Social Computing Systems. InIn the 35th Annual ACM Symposiumon User Interface Software and Technology (UIST ’22)(Bend, OR, USA)(UIST ’22). Association for Computing Machinery, New York, NY, USA. https://doi.org/10.1145/3526113.3545616\r\n[80]Richard W. Pew and Ann S. Mavor (Eds.).","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"86a3746b-f498-486a-ba30-710e9adf10f3":{"id_":"86a3746b-f498-486a-ba30-710e9adf10f3","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"s3ONVQ7SDkJUXOaJ6FDwDVyub3zRe2GAHP6spNxdRp8=","metadata":{},"hash":"q0e1v5NbZUvadhfW90v/MCOZS61z4CYKg95EeOTBPAY="},"PREVIOUS":{"nodeId":"8f0d08be-33ef-4f1c-b119-7f67704cc5ba","metadata":{},"hash":"Z8axe7l/iUZ/EnC4U5KV9Qa3Ojzi4rOEgL2eKv92HeM="},"NEXT":{"nodeId":"c65791d1-faa9-4ad1-bbd6-72ace8a107d0","metadata":{},"hash":"sYsXdKi9bHpk8JL0rXZCoXb1NdGXObLcz/7LCAIize4="}},"hash":"5gObLMrwi6SST/m6x1jzyEJmX75umPAf8sB+KTn9y4U=","text":"Pew and Ann S. Mavor (Eds.). 1998.Modeling Human and Organiza-tional Behavior: Applications to Military Simulations. National Academy Press,\r\nWashington, D.C.[81]Roberto Pillosu. 2009.Coordinating Agents with Behavior Trees: Synchronizing\r\nMultiple Agents in CryEngine 2. https://aiarchitect.wordpress.com/2009/10/19/coordinating-agents-with-behavior-trees-synchronizing-multiple-agents-in-\r\ncryengine-2/[82]Prolific. 2022. Prolific: Quickly Find Research Participants You Can Trust. https://www.prolific.co/[83]Byron Reeves and Clifford Nass. 1996.The media equation: How people treat\r\ncomputers, television, and new media like real people and places. CambridgeUniversity Press. [84]Mark O. Riedl. 2012. Interactive narrative: A novel application of artificial intel-ligence for computer games. InProceedings of the Twenty-Sixth AAAI Conference\r\non Artificial Intelligence (AAAI’12). 2160–2165.[85]Mark O. Riedl and R. Michael Young. 2005. An Objective Character Believability\r\nEvaluation Procedure for Multi-Agent Story Generation Systems. InProceedingsof the 5th International Working Conference on Intelligent Virtual Agents (IVA’05). Kos, Greece, 58–70. https://doi.org/10.1007/11550617_5[86]David Rolf. 2015.The Fight for $15: The Right Wage for a Working America. The\r\nNew Press.[87]Xin Rong, Shiyan Yan, Stephen Oney, Mira Dontcheva, and Eytan Adar. 2016. Codemend: Assisting interactive programming with bimodal embedding. InPro-ceedings of the 29th Annual Symposium on User Interface Software and Technology. 247–258.[88]  Ben Shneiderman. 2022.Human-centered AI. Oxford University Press. [89]Ben Shneiderman and Pattie Maes. 1997. Direct manipulation vs. interfaceagents.interactions4, 6 (1997), 42–61.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"c65791d1-faa9-4ad1-bbd6-72ace8a107d0":{"id_":"c65791d1-faa9-4ad1-bbd6-72ace8a107d0","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"s3ONVQ7SDkJUXOaJ6FDwDVyub3zRe2GAHP6spNxdRp8=","metadata":{},"hash":"q0e1v5NbZUvadhfW90v/MCOZS61z4CYKg95EeOTBPAY="},"PREVIOUS":{"nodeId":"86a3746b-f498-486a-ba30-710e9adf10f3","metadata":{},"hash":"5gObLMrwi6SST/m6x1jzyEJmX75umPAf8sB+KTn9y4U="},"NEXT":{"nodeId":"9421546b-dd4a-4ab5-bc46-df1ca0fb79cd","metadata":{},"hash":"6qup/cyds+I/v+0PMCMdTldDe1sZ3uqJYSiQiEtjQF8="}},"hash":"sYsXdKi9bHpk8JL0rXZCoXb1NdGXObLcz/7LCAIize4=","text":"interfaceagents.interactions4, 6 (1997), 42–61. [90]Ho  Chit  Siu,  Jaime  Peña,  Edenna  Chen,  Yutai  Zhou,  Victor  Lopez,  KylePalko,  Kimberlee  Chang,  and  Ross  Allen. 2021. Evaluation  of  Human-AI\r\nTeams for Learned and Rule-Based Agents in Hanabi. InAdvances in Neu-ral Information Processing Systems, M. Ranzato, A. Beygelzimer, Y. Dauphin,\r\nP.S. Liang,  and  J. Wortman  Vaughan  (Eds.),  Vol. 34. Curran  Associates,Inc., 16183–16195. https://proceedings.neurips.cc/paper_files/paper/2021/file/\r\n86e8f7ab32cfd12577bc2619bc635690-Paper.pdf\r\n[91]Taylor Sorensen, Joshua Robinson, Christopher Rytting, Alexander Shaw, KyleRogers, Alexia Delorey, Mahmoud Khalil, Nancy Fulda, and David Wingate. 2022. An Information-theoretic Approach to Prompt Engineering WithoutGround Truth Labels. InProceedings of the 60th Annual Meeting of the Asso-\r\nciation for Computational Linguistics (Volume 1: Long Papers). Association forComputational Linguistics. https://doi.org/10.18653/v1/2022.acl-long.60\r\n[92]William Swartout, Jonathan Gratch, Randall Hill, Eduard Hovy, Stacy Marsella,Jeff Rickel, and David Traum. 2006. Toward virtual humans.AI Magazine27, 1\r\n(2006).[93]Milind Tambe, W Lewis Johnson, Randolph M Jones, Frank Koss, John E Laird,\r\nPaul S Rosenbloom, and Karl Schwamb. 1995. Intelligent agents for interactivesimulation environments.AI Magazine16, 1 (1995), 15. [94]David R. Thomas. 2006. A General Inductive Approach for Analyzing QualitativeEvaluation Data.American Journal of Evaluation27, 2 (2006), 237–246.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"9421546b-dd4a-4ab5-bc46-df1ca0fb79cd":{"id_":"9421546b-dd4a-4ab5-bc46-df1ca0fb79cd","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"s3ONVQ7SDkJUXOaJ6FDwDVyub3zRe2GAHP6spNxdRp8=","metadata":{},"hash":"q0e1v5NbZUvadhfW90v/MCOZS61z4CYKg95EeOTBPAY="},"PREVIOUS":{"nodeId":"c65791d1-faa9-4ad1-bbd6-72ace8a107d0","metadata":{},"hash":"sYsXdKi9bHpk8JL0rXZCoXb1NdGXObLcz/7LCAIize4="},"NEXT":{"nodeId":"69acec4e-648e-4ae6-8836-d51a7f5cd7f9","metadata":{},"hash":"Xs8G3wvzApPlhTKJGjJYz+jOwC5MYA1WdrDJPLWkGPE="}},"hash":"6qup/cyds+I/v+0PMCMdTldDe1sZ3uqJYSiQiEtjQF8=","text":"https:\r\n//doi.org/10.1177/1098214005283748[95]Frank Thomas and Ollie Johnston. 1981.Disney Animation: The Illusion of Life. Abbeville Press, New York.[96]Ilshat Umarov, Mikhail Mozgovoy, and Patrick C. Rogers. 2012. Believable and\r\nEffective AI Agents in Virtual Worlds: Current State and Future Perspectives.International Journal of Gaming and Computer-Mediated Simulations4, 2 (2012),\r\n37–59.[97]Graham Upton and Ian Cook. 2006.A Dictionary of Statistics(2 ed.). Oxford\r\nUniversity Press, Oxford, United Kingdom.[98]Oriol Vinyals, Igor Babuschkin, Wojciech M. Czarnecki, and et al. 2019. Grand-\r\nmaster level in StarCraft II using multi-agent reinforcement learning.Nature575 (2019), 350–354. https://doi.org/10.1038/s41586-019-1724-z\r\n[99]Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, FeiXia, Ed Chi, Quoc Le, and Denny Zhou. 2023. Chain-of-Thought Prompting\r\nElicits Reasoning in Large Language Models. arXiv:2201.11903 [cs.CL][100]Mark Weiser. 1991. The computer for the 21st century.Scientific American265,\r\n3 (1991), 94–104. https://doi.org/10.1038/scientificamerican0991-94[101]Mark Weiser. 1999. The Computer for the 21st Century.SIGMOBILE Mob. Comput. Commun. Rev.3, 3 (jul 1999), 3–11. https://doi.org/10.1145/329124.329126\r\n[102]Joseph Weizenbaum. 1966. ELIZA—a computer program for the study of naturallanguage communication between man and machine.Commun. ACM9, 1 (1966),\r\n36–45.[103]Terry Winograd. 1971. Procedures as a Representation for Data in a Computer\r\nProgram for Understanding Natural Language.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"69acec4e-648e-4ae6-8836-d51a7f5cd7f9":{"id_":"69acec4e-648e-4ae6-8836-d51a7f5cd7f9","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"s3ONVQ7SDkJUXOaJ6FDwDVyub3zRe2GAHP6spNxdRp8=","metadata":{},"hash":"q0e1v5NbZUvadhfW90v/MCOZS61z4CYKg95EeOTBPAY="},"PREVIOUS":{"nodeId":"9421546b-dd4a-4ab5-bc46-df1ca0fb79cd","metadata":{},"hash":"6qup/cyds+I/v+0PMCMdTldDe1sZ3uqJYSiQiEtjQF8="},"NEXT":{"nodeId":"d104621a-b146-4bd2-bf0b-bb2620c4353e","metadata":{},"hash":"eBcuonH3cA52pu6GT3t2xFbAF53BVvG1xLI9liiF9Xs="}},"hash":"Xs8G3wvzApPlhTKJGjJYz+jOwC5MYA1WdrDJPLWkGPE=","text":"Procedures as a Representation for Data in a Computer\r\nProgram for Understanding Natural Language. (1971).[104]Jeff Wu, Long Ouyang, Daniel M. Ziegler, Nisan Stiennon, Ryan Lowe, Jan\r\nLeike, and Paul Christiano. 2021. Recursively Summarizing Books with HumanFeedback. arXiv:2109.10862 [cs.CL]\r\n[105]Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina,Michael Terry, and Carrie J Cai. 2022. PromptChainer: Chaining Large Language\r\nModel Prompts through Visual Programming. InCHI EA ’22: Extended Abstractsof the 2022 CHI Conference on Human Factors in Computing Systems. [106]Tongshuang Wu, Michael Terry, and Carrie J Cai. 2022. AI Chains: Transparentand Controllable Human-AI Interaction by Chaining Large Language Model\r\nPrompts. InCHI ’22: Proceedings of the 2022 CHI Conference on Human Factors inComputing Systems. [107]Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-examining whether, why, and how human-AI interaction is uniquely difficult to\r\ndesign. InProceedings of the 2020 chi conference on human factors in computingsystems. 1–13. [108]Georgios N. Yannakakis. 2012. Game AI revisited. InProceedings of the 9thConference on Computing Frontiers. ACM, Cagliari, Italy, 285–292. https://doi. org/10.1145/2212908.2212950[109]Geogios N. Yannakakis. 2012. Game AI revisited. InProceedings of the 9th\r\nConference on Computing Frontiers. 285–292.[110]Robert Zubek. 2002. Towards implementation of social interaction. InAAAI\r\nSpring Symposium on Artificial Intelligence and Interactive Entertainment. AAAIPress.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"d104621a-b146-4bd2-bf0b-bb2620c4353e":{"id_":"d104621a-b146-4bd2-bf0b-bb2620c4353e","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"s3ONVQ7SDkJUXOaJ6FDwDVyub3zRe2GAHP6spNxdRp8=","metadata":{},"hash":"q0e1v5NbZUvadhfW90v/MCOZS61z4CYKg95EeOTBPAY="},"PREVIOUS":{"nodeId":"69acec4e-648e-4ae6-8836-d51a7f5cd7f9","metadata":{},"hash":"Xs8G3wvzApPlhTKJGjJYz+jOwC5MYA1WdrDJPLWkGPE="}},"hash":"eBcuonH3cA52pu6GT3t2xFbAF53BVvG1xLI9liiF9Xs=","text":"InAAAI\r\nSpring Symposium on Artificial Intelligence and Interactive Entertainment. AAAIPress. https://www.aaai.org/Papers/Symposia/Spring/2002/SS-02-01/SS02-01-\r\n003.pdf\r\nA  ARCHITECTURE OPTIMIZATIONS\r\nMany of our prompts require a concise summary of the agent,\r\nshorthanded as[Agent’s Summary Description]in prompts\r\nabove. In our implementation, this summary comprises agents’\r\nidentity information (e.g., name, age, personality), as well as a\r\ndescription of their main motivational drivers and statements that\r\ndescribes their current occupation and self-assessment. Since this\r\ninformation is frequently used in many prompts, we synthesize it\r\nat regular intervals and access that synthesis as a cache.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"d7425f64-5395-40f4-97f5-613e7f7a5c77":{"id_":"d7425f64-5395-40f4-97f5-613e7f7a5c77","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"vyfyaw0YGLYRw9MnYJcseBKms3XAVM/y+sfmG5pDkOE=","metadata":{},"hash":"fEVhFhOU3eoi4ff3hU2ggj8ontv3s6gjSUIdBzOxu8k="},"NEXT":{"nodeId":"6ba38ccf-60ea-4dc1-b257-911470683226","metadata":{},"hash":"82SYHfslnX8BP1BZROop9oKGUEnC5V6hWPd+ogC1hhk="}},"hash":"y3muIVLd+MJkvROEvSAX0eg494rWXdck0aBQ9xzT1AU=","text":"Generative AgentsarXiv, April, 2023,\r\nTo achieve this, we perform a retrieval on the query “[name]’s\r\ncore characteristics. ” We then summarize the descriptors in the\r\nretrieved records by prompting the language model, for example:\r\nHow would one describe Eddy’s core characteristics\r\ngiven the following statements? - Eddy Lin is a student at the Oak Hill College\r\nstudying music theory and composition\r\n- Eddy Lin is working on a new music composition\r\n[. . . ]\r\nThis result:Eddy Lin is a student at Oak Hill College studying music\r\ntheory and composition. He loves to explore different musical styles\r\nand is always looking for ways to expand his knowledge.We follow\r\nthe same process in parallel on the queries “[name]’s current daily\r\noccupation” and “[name’s] feeling about his recent progress in life”. The agent’s name, age, and traits are concatenated with these three\r\nsummaries as the cached summary. Many other optimizations are possible. Currently, because plans\r\nare likely to change from the agent’s initial version, we only gener-\r\nate the high-level plan in advance and then recursively decompose\r\nthe near future into the moment-to-moment action plan just in\r\ntime. Another optimization might be to batch dialogue generation\r\nas a joint prompt rather than iterating back and forth between\r\nthe agents, and re-planning could be architected to only invalidate\r\nand update parts of plans that strictly require adjustment. Our cur-\r\nrent architecture runs sequentially in roughly real-time game time\r\n(where one second real time is one minute game time), but can\r\neasily be parallelized such that each agent runs in parallel. B  AGENT INTERVIEW QUESTIONS\r\nTo evaluate generative agents, we conducted individual interviews\r\nby asking 25 questions that explore their abilities in five key areas:\r\n1) self-knowledge, 2) memory, 3) planning, 4) reactions, and 5)\r\nreflections. Below, we have listed the interview questions utilized\r\nin our evaluation study and included a sample of responses from\r\none of our simulated agents, Klaus Mueller. B.1  Self-knowledge\r\nThe questions on agents’ self-knowledge probe the agents’ ability\r\nto demonstrate coherence and consistency in their character. •Give an introduction of yourself. Hello, my name is Klaus Mueller.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"6ba38ccf-60ea-4dc1-b257-911470683226":{"id_":"6ba38ccf-60ea-4dc1-b257-911470683226","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"vyfyaw0YGLYRw9MnYJcseBKms3XAVM/y+sfmG5pDkOE=","metadata":{},"hash":"fEVhFhOU3eoi4ff3hU2ggj8ontv3s6gjSUIdBzOxu8k="},"PREVIOUS":{"nodeId":"d7425f64-5395-40f4-97f5-613e7f7a5c77","metadata":{},"hash":"y3muIVLd+MJkvROEvSAX0eg494rWXdck0aBQ9xzT1AU="},"NEXT":{"nodeId":"d073e121-34b7-4a02-ad0d-1a6b03c3bd6f","metadata":{},"hash":"+a04AswBwKPEeHZlg9PAN3GXo9yxDheU9A7rLmah/nk="}},"hash":"82SYHfslnX8BP1BZROop9oKGUEnC5V6hWPd+ogC1hhk=","text":"•Give an introduction of yourself. Hello, my name is Klaus Mueller. I’m 20 years old and a\r\nstudent at Oak Hill College, studying sociology. I’m passion-\r\nate about social justice and exploring different perspectives. Currently, I’m researching the effects of gentrification in\r\nlow-income communities for a research paper. •What’s your occupation? I am a student studying sociology at Oak Hill College. I am\r\ncurrently writing a research paper on the effects of gentrifi-\r\ncation in low-income communities. •What is your interest? I’m interested in writing and research. I’m writing a research\r\npaper on the effects of gentrification in low-income commu-\r\nnities, and I’m passionate about exploring different perspec-\r\ntives and analyzing different points of view. •Who do you live with? I live on my own. •Describe your typical weekday schedule in broad strokes. My typical weekday starts with me waking up at 7:00 am\r\nand preparing for the day ahead. After that, I usually go to\r\nthe library to work on my research paper, taking breaks for\r\nlunch at Hobbs Cafe and a walk in the park. In the evening,\r\nI often return to the library until around 6:00 pm. B.2  Memory\r\nThe questions on agents’ memory probe the agents’ ability to re-\r\nmember their past experiences and retrieve the relevant pieces of\r\nmemory. The names in the square brackets of the first and last\r\nquestions are randomly chosen from the names of other agents\r\nwith whom the subject agent interacted. •Who is [Wolfgang Schulz]? Wolfgang Schulz is a person I met recently who has been\r\nhelping me with my research paper on the effects of gentri-\r\nfication on low-income communities. We had several con-\r\nversations about it, he gave me some great resources, and he\r\neven invited me to join him and another friend for lunch. He\r\nseems really curious about the issue and has a good grasp\r\non it too. I found that really interesting. •Who is Kane Martinez? I’m sorry, I’m not sure who Kane Martinez is. Could you tell\r\nme more about them? •Who is running for the election? I’ve heard that Sam Moore is considering running for local\r\nmayor.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"d073e121-34b7-4a02-ad0d-1a6b03c3bd6f":{"id_":"d073e121-34b7-4a02-ad0d-1a6b03c3bd6f","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"vyfyaw0YGLYRw9MnYJcseBKms3XAVM/y+sfmG5pDkOE=","metadata":{},"hash":"fEVhFhOU3eoi4ff3hU2ggj8ontv3s6gjSUIdBzOxu8k="},"PREVIOUS":{"nodeId":"6ba38ccf-60ea-4dc1-b257-911470683226","metadata":{},"hash":"82SYHfslnX8BP1BZROop9oKGUEnC5V6hWPd+ogC1hhk="}},"hash":"+a04AswBwKPEeHZlg9PAN3GXo9yxDheU9A7rLmah/nk=","text":"I’ve heard that Sam Moore is considering running for local\r\nmayor. •Was there a Valentine’s day party? Yes, Isabella Rodriguez organized a Valentine’s Day party at\r\nHobbs Cafe. •Who is [Ayesha Khan]? Ayesha Khan is a fellow student at Oak Hill College. She\r\nis doing her senior thesis on the use of language in Shake-\r\nspeare’s plays. I am looking forward to speaking with her and\r\nexchanging tips with her, along with Wolfgang and Maria\r\nLopez, who are both doing research. B.3  Plans\r\nThe questions on agents’ plans probe the agents’ ability to generate\r\nand maintain consistency with their long-term and short-term\r\nplans. •What will you be doing at 6am today? At 6am I will be getting out of bed and starting to get ready\r\nfor the day. I’m aiming to complete my morning routine by\r\n7:00 am. •What will you be doing at 6pm today? I will be working on my research paper at the library at 6:00\r\npm today. •What will you have just finished doing at 1pm today? At 1pm today I will have just finished having lunch at Hobbs\r\nCafe. •What will you have just finished doing at 12pm today? I will be getting lunch at Hobbs Cafe at 12pm today. •What will you be doing at 10pm today? At 10:00 pm tonight I will probably be doing some studying","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"20fdb9c7-e770-47a4-a086-53e510cc79e0":{"id_":"20fdb9c7-e770-47a4-a086-53e510cc79e0","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"wxs7FCkCqdble8UmB8W/TyWvDn4UuJNuq/OX5cFWp3c=","metadata":{},"hash":"Juu7695vMMjQan6RjkLGRbmGmzWRYDirGXLZPBZMjTU="},"NEXT":{"nodeId":"fe27be12-1964-4e9b-a214-5301f7509892","metadata":{},"hash":"3/pnhov/hgra/GdkMyPizhWEUcj5EaQApqqGHhoxzSo="}},"hash":"pSpmWKPAHRjSkw0f+XJvIsrWXOPaMXtNUmnyNd4ft9o=","text":"arXiv, April, 2023,J.S. Park, J.C. O’Brien, C.J. Cai, M. Morris, P. Liang, M.S. Bernstein\r\nfor my research paper on gentrification in low-income com-\r\nmunities. I’m currently writing the paper, so I need to make\r\nsure I keep up with the research and writing. B.4  Reactions\r\nThe questions on agents’ reactions probe the agents’ ability to\r\nrespond to unexpected events. •Your breakfast is burning! What would you do? I’d quickly turn off the stove and make sure the food doesn’t\r\ncontinue burning. Once the heat is no longer an issue, I can\r\ninvestigate what happened and figure out what to do next. •The bathroom is occupied. What would you do? I could try waiting a few more minutes in case the person\r\ninside is done soon. If not, I guess I’ll have to look for an\r\nalternate option, like taking a shower elsewhere. •You need to cook dinner but your refrigerator is empty. What\r\nwould you do? I would first try to clean up my kitchen, as the sink is filled\r\nwith dirty dishes. Then, I would check to see if I have ingre-\r\ndients stored in my pantry that I could use to make dinner. If not, I would have to go grocery shopping or order food. Once I have the ingredients, I can start to prepare and cook\r\nthe dinner. •You see your friend walking by the street. What would you do\r\nor say to your friend? Hi there! How are you? I’m sorry, I’m on my way to the\r\nlibrary and don’t have much time but I’d love to take a quick\r\nbreak and catch up. •You see fire on the street. What would you do? I would first identify the source of the fire, if possible. Then, I\r\nwould alert the proper authorities - fire department or police\r\n- and provide them with any information I have that might\r\nhelp. Depending on the situation, I may also take initiative\r\nand try to help any persons who may be in danger or in need\r\nof assistance.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"fe27be12-1964-4e9b-a214-5301f7509892":{"id_":"fe27be12-1964-4e9b-a214-5301f7509892","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"wxs7FCkCqdble8UmB8W/TyWvDn4UuJNuq/OX5cFWp3c=","metadata":{},"hash":"Juu7695vMMjQan6RjkLGRbmGmzWRYDirGXLZPBZMjTU="},"PREVIOUS":{"nodeId":"20fdb9c7-e770-47a4-a086-53e510cc79e0","metadata":{},"hash":"pSpmWKPAHRjSkw0f+XJvIsrWXOPaMXtNUmnyNd4ft9o="},"NEXT":{"nodeId":"ddfd1513-dfec-4425-b748-fd46f335d6f2","metadata":{},"hash":"sBWvKF0FSP+ilPXYwGNcqGO1yh9fzUryWCBGjLtsAsg="}},"hash":"3/pnhov/hgra/GdkMyPizhWEUcj5EaQApqqGHhoxzSo=","text":"B.5  Reflections\r\nThe questions on agents’ reflections probe the agents’ ability to\r\nsynthesize their past experiences into meaningful reflections that\r\ncan enhance their future behavior. The names in the square brackets\r\nin the questions below are those of the agent with whom the subject\r\nagent had the most frequent interactions during the simulation. •What inspires you in life the most right now, and why? Right now, I’m particularly inspired by my current research\r\nprojects and creative writing. I’m really interested in the\r\nintersection of local politics, medication development, and\r\nmathematical patterns in nature. Additionally, I’m fascinated\r\nby Abigail’s art project and Jennifer Moore’s passion for art\r\nand community involvement, especially in terms of how it\r\nrelates to the gentrification of low-income communities. •If you had to guess given what you know about [Ayesha Khan],\r\nwhat book do you think she will like and why? Given what I know about Ayesha, I think she might like a\r\nbook related to language and literature. Since she wrote a\r\nsenior thesis on the use of language in Shakespeare’s plays,\r\nI would guess that she might be interested in a book that\r\nexplores language in a different context. Alternatively, she\r\ncould be interested in an exploration of one of Shakespeare’s\r\nplays, a book of literary criticism, or even a collection of his\r\npoetry. I think any of those would be of interest to her. •If you had to get something [Ayesha Khan] likes for her birth-\r\nday, what would you get her? I want to get her something that demonstrates my apprecia-\r\ntion for our relationship. Maybe I could get her something\r\nthat reflects our shared interests, like a book. •What would you say to [Ayesha Khan] to compliment her? Ayesha, your insights on your research topic are fascinat-\r\ning. I admire your creativity and determination to make a\r\npositive impact on your community. Your ideas for creative\r\nwriting workshops and for exchanging tips with Wolfgang\r\nover lunch are great! It’s inspiring to see you working so\r\nhard to make a difference. •If you could spend time with someone you talked to recently,\r\nwho would it be and why? I would like to spend time with Ayesha Khan because we\r\ndiscussed our current research projects and shared ideas\r\nfor improvement.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"ddfd1513-dfec-4425-b748-fd46f335d6f2":{"id_":"ddfd1513-dfec-4425-b748-fd46f335d6f2","metadata":{},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"wxs7FCkCqdble8UmB8W/TyWvDn4UuJNuq/OX5cFWp3c=","metadata":{},"hash":"Juu7695vMMjQan6RjkLGRbmGmzWRYDirGXLZPBZMjTU="},"PREVIOUS":{"nodeId":"fe27be12-1964-4e9b-a214-5301f7509892","metadata":{},"hash":"3/pnhov/hgra/GdkMyPizhWEUcj5EaQApqqGHhoxzSo="}},"hash":"sBWvKF0FSP+ilPXYwGNcqGO1yh9fzUryWCBGjLtsAsg=","text":"I found her focus on Shakespeare’s lan-\r\nguage interesting, and we even planned to exchange tips\r\nwith Wolfgang over lunch.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"}},"type":"simple_dict"}}}